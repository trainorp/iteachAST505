{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Instructions:\n",
    "Please complete the workbook below. Some of the calculations are already ready to be \"run\". However, please read the text carefully to find questions that you should answer for credit. Remember that to answer a question in text, you click \"insert\", then \"insert cell below\", switch the input from \"code\" to \"markdown\", type your answer, and finally click the run button to set your text in stone. In a few questions, you will need to do some calculations on your own. Hint: for these calculations you can copy, paste, and modify code that is above the calculation that you need to do. You may work by yourself or in groups of 2. Please remember to put your name on top, remember to save the workbook, and remember to upload to Canvas.\n",
    "\n",
    "**Please read** Please run the code below and ignore the output. This code is simply setting the height and width of the plots we will make later on and loading a set of software \"tidyverse\" that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 6, repr.plot.height = 4)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Inference regarding a population median\n",
    "Today we will start with inference about population medians. Our first dataset is about commute times for the cities of Boston, Houston, Minneapolis, and Washington. In the American Housing Survey, survey respondents were asked about the time it takes them to get to work, and the distance they travel to get to work. We have a random sample of 500 survey participants from each city taken in 2007."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Loading the data\n",
    "First we will load the data like we did in the last lab. This data is in a \"package\" called \"Stat2Data\". Just like last lab, we will need to install the package and load the data. Please run the command below to install the package and wait for the star to go away before preceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('Stat2Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the \"Stat2Data\" package and the dataset called \"MetroCommutes\" using the \"library\" and \"data\" commands. You should not see any output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Stat2Data)\n",
    "data(MetroCommutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at what the first 6 observations from this data look like. We will use the \"head\" command which prints the first few observations of a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(MetroCommutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above, we have the city, the distance of the commute (in miles), and the time of the commute (in minutes). Let's make a histogram of the time of commute variable for the entire dataset. We will use the \"hist\" function with a \"breaks\" argument telling R to make the histogram bins go from 0 to 180 by 10's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(MetroCommutes$Time, breaks = seq(0, 180, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you.** Looking at the above histogram, do you think that the commute times are normally distributed? Please answer below (insert new cell below, change to markdown, and type answer). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you.** Do you think that the mean or median will be a better measure of centrality for the commute time data? (if we want an idea of what a \"typical\" commute time is). Please answer below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Using Q-Q plots to check \"normality\"\n",
    "Now, let's use a Q-Q plot to check if our data appears to be similar to a normal distribution. Remember to do this we will compare the quantiles of our data against the quantiles from a standard normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step will be to order our time of commute from smallest to largest. To do this we will order the entire dataset by the \"time of commute\" variable. To do this we will first make a new variable called \"timeOrder\" that records the order of each of the observations of \"time of commute\". For example, the smallest value will be assigned a 1, the second smallest value will be assigned a 2, and so on. Please run the code to create this variable using the \"order\" function. Nothing will be returned when you do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeOrder <- order(MetroCommutes$Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our \"timeOrder\" variable that tells us the order of each of our \"time of commute\" observations, let's take a look at what the first 20 values of this variable are. We will get the 1 through 20th values by adding \"[1:20]\" to the end of our variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeOrder[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we have a variable that gives the order of our \"time of commute\" variable, we will use this variable to sort the entire dataset. To do this we will make a new dataset called \"MetroCommutesOrdered\" that will be the \"MetroCommutes\" dataset but ordered by \"time of commute\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered <- MetroCommutes[timeOrder,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's print out the first 25 observations of this newly ordered dataset. Remember, this dataset will be ordered by the \"Time\" variable, but not by any other variable (like distance): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered[1:25,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will need to add a column to this dataset that tells us the order of each observation(time). Before we do this lets determine how many observations there are, and save this number as \"n\". We can do this using the \"nrow\" command which tells us how many rows there are in a dataset. Please run the next two lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(MetroCommutesOrdered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- nrow(MetroCommutesOrdered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved the number of observations as \"n\", we are ready to add the new column to our dataset that tells us the order of the observation (in terms of the \"Time of commute\" variable). We will call this new column (or variable) \"i\". Please run the code below to create this new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered$i <- 1:n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at what we did in the last step by printing out the first 25 observations in our ordered dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered[1:25,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice many of the observations have the same \"time of commute\" value but have different \"i\" values. When we are making a Q-Q plot this is the way we will handle tied values. Okay, next we need to add a column that tells us what the quantile is for each of the \"time of commute\" observations. We will use the formula we discussed in lecture: $(i-0.5)/n$. We will save this as a new column (or variable) in our dataset called \"Quantile\". Please run the code below to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered$Quantile <- (MetroCommutesOrdered$i - 0.5) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's take a look at what we have just done by printing the first 25 rows of our ordered dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered[1:25,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now our next setep is to determine the value from a standard normal distribution that is for each of the quantiles. For example, we know that $z_{0.025} = -1.96$, $z_{0.50} = 0$, and $z_{0.95} = 1.645$. In the next two lines of code we will use the \"qnorm\" function with the default $\\mu =0$ and $\\sigma=1$, to find the values of $z_{0.025} = -1.96$, and $z_{0.50} = 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnorm(0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnorm(.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you**. Below use the \"qnorm\" function to find the 95th percentile $z_{0.95}$. To do this insert a new cell, keep it as a code cell, copy, paste, and modify: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now what we want to do is determine the standard normal distribution value for every one of the quantiles that we have added as a column to our dataset. Below, we will use the \"qnorm\" function again to do this. We will save the values as a new column (or variable) in the dataset called \"NormalValue\". Please run the code below to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered$NormalValue <- qnorm(MetroCommutesOrdered$Quantile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the first 25 observations again to see what we have just done: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered[1:25,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to make our Q-Q plot. We will do this using the plot command with two arguments. The first is the \"NormalValue\" column from our dataset. This will be the value on the horizontal axis. The second is the \"Time\" variable from our dataset, this will be the vertical axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(MetroCommutesOrdered$NormalValue, MetroCommutesOrdered$Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you** Now that you have seen this Q-Q plot, do you think that if you drew a straight line through the plot, the dots would be close to this line? Or would many of them lie off of the line? Please answer the question below with a sentence (insert new cell below, change to markdown, and type your response). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! We just did a ton of work to make that Q-Q plot. But, as you might expect, R has a command that can do all of it in one step. To do this we will use our original dataset \"MetroCommutes\" (we don't even need to sort the data!). Please run the code below to check it out: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqnorm(MetroCommutes$Time, frame = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to add a \"best fit\" line to this plot (we will discuss these lines later in the course), we can use one more function \"qqline\" to add it to the plot. Please run the code below to see this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqnorm(MetroCommutes$Time, frame = FALSE)\n",
    "qqline(MetroCommutes$Time, col = \"red\", lwd = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you**. Do the data points sit close to the line, or would you say some of them are far away? (insert new cell below, change to markdown, and type your response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you**. If the \"Time of commute\" variable was normally distributed, how would the Q-Q plot be different than what we see above? Please answer the question below with a sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) A point estimate and confidence interval for the median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's suppose we want to generate a point estimate and 95% confidence interval for the population median of commute times. We know that the sample median is the best point estimate of the population median--so this part will be easy. Let's determine the sample median of commute times using R: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median(MetroCommutes$Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you**. Given the sample size from this dataset, will we use the \"small sample\" method or the normal approximation method? Please answer the question below. (insert new cell below, change to markdown, and type your response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will construct the 95% confidence interval. For this confidence interval will use the formula: $(M_L, M_U) = (y_{(L_{\\alpha/2})}, y_{(U_{\\alpha/2})})$, where $L_{\\alpha/2}=C_{\\alpha(2),n}+1$ and $U_{\\alpha/2}=n-C_{\\alpha(2),n}$. To compute $C_{\\alpha(2),n}$, we will use the normal approximation:\n",
    "$C_{\\alpha(2),n} \\approx \\frac{n}{2} - z_{\\alpha/2}\\sqrt{n/4}$. Luckily, we already know $n$, so all we need to determine is $z_{\\alpha/2}$. \n",
    "\n",
    "**Question for you.** Below, please determine the value of $z_{\\alpha/2}$ and save it as \"za\". Please save it as exactly \"za\", as we will use this in later calculations. As an example, if I wanted to find $z_{\\alpha/2}$, and $\\alpha = .20$ and save it as \"za\", I would type \"za <- qnorm(.10, lower.tail = FALSE)\" or \"za <- qnorm(1-.10, lower.tail = TRUE)\". Please create \"za\" below (remember to insert a new cell below and keep in \"code\" rather than markdown; also remeber to run the code when you have finished):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now that we have $z_{\\alpha}$, let's determine $C_{\\alpha(2),n}$. First we will show the value, then in the next line of code we will save it as \"ca\". Please run both lines below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n / 2 - za * sqrt(n / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca <- n / 2 - za * sqrt(n / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will need to create $L_{\\alpha/2}=C_{\\alpha(2),n}+1$ and $U_{\\alpha/2}=n-C_{\\alpha(2),n}$. \n",
    "\n",
    "**Question for you.** Below please create $L_{\\alpha/2}$ and save it as \"la\", and create $U_{\\alpha/2}$ and save it as \"ua\" (remember to insert a new cell below and keep in \"code\" rather than markdown; also remeber to run the code when you have finished). You can create \"la\" and \"ua\" in separate cells or as separate lines in the same cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to finally determine our 95% confidence interval we need to use: $(M_L, M_U) = (y_{(L_{\\alpha/2})}, y_{(U_{\\alpha/2})})$. So we need to round $L_{\\alpha/2}$ and $U_{\\alpha/2}$ to the nearest whole number. To do this we will use the \"round\" command. Please run the two lines of code below to see the rounded values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(ua)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we are looking for the 957th and 1044th values of the \"time of commute\" variable in our dataset. Let's determine what these are. Remeber that earlier we created a new dataset that was sorted or ordered by the values of \"time of commute\"--we will work with this dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered[957,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutesOrdered[1044,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as you might have guessed, there is an R function that does all of that for you. However, there are multiple functions that can determine median confidence intervals in R, we want the \"MedianCI\" function from the package \"DescTools\". We will need to first install this package, then load this package (with the \"library\" function), and then we will be able to use this \"MedianCI\" function. Please remember when installing a package to wait for the star to go away before proceeding: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('DescTools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(DescTools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MedianCI(MetroCommutes$Time, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4) Hypothesis testing using the \"Sign Test\"\n",
    "Now, let's suppose you wanted to determine if there was evidence to support the hypothesis that the median \"time of commute\" is less than 25.25 minutes. Let's test this hypothesis with $\\alpha = 0.05$.\n",
    "\n",
    "**Question for you.** Below please state what the null and alternative hypotheses would be for this test. You can use plain English instead of symbols (or you can use symbols--your choice). Remember to insert cell below, and change to markdown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first, we will work towards computing a test statistic. For this we need to compute $W_i = y_i - M_0$. The code below will compute each $W_i$ and add it as a new column (variable) to our dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutes$W <- MetroCommutes$Time - 25.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at this new variable $W$ by printing out the first 20 observations from this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutes[1:20,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you**. Once we have determined the $W_i$'s what is the next step? What do we need to do next before we can determine $B$? Please answer the question below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so to determine if each $W_i$ is positive (or negative) we can use the \"sign\" function. This function will return a -1 if the $W_i$ is negative or a 1 if the $W_i$ is positive: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign(MetroCommutes$W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's save those sign values as a new column in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutes$Sign <- sign(MetroCommutes$W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the first 20 observations of the dataset look like now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutes[1:20,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now to calculate $B$, we need to count how many of the $W_i$'s are positive. There are a few different ways that we can do this--we will use one way. What we will do is modify our column that checked to see if $W_i$ was positive or negative. Right now we cannot sum the \"Sign\" variable to compute $B$ because it returned \"-1\" when $W_i$ is negative. We need this variable to return \"0\" if $W_i$ is negative and \"1\" if $W_i$ is positive. The code below will find values of the \"Sign\" variable that are \"-1\" and turn them into \"0\" instead: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutes$Sign[MetroCommutes$Sign == -1] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now that this worked by printing out the first 20 observations for our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetroCommutes[1:20,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we are able to compute $B$ from $W$. To do this we can use the sum function to add up all of the values in our \"Sign\" variable from the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(MetroCommutes$Sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's save this value as \"B\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B <- sum(MetroCommutes$Sign[MetroCommutes$Sign == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the normall approximation to the Binomial distribution here, we need to calculate $B^* =\\frac{B-n/2}{\\sqrt{n/4}}$. The good news is we already have $n$ from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BStar <- (B - n / 2) / sqrt(n / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BStar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to determine a rejection region that is consistent with our hypotheses. **Question for you**. Do we have a one-sided rejection region for this test or two-sided? If one-sided, which tail will the rejection region be in? Please answer the questions below (insert new cell, change to markdown and type your response):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now to find the quantile from the standard normal distribution that gives us a right-tailed probability of $\\alpha$ we can use \"qnorm(alpha, lower.tail = FALSE)\", and to determine the quantile that gives us a left-tailed probability of $\\alpha$, we can use \"-qnorm(alpha, lower.tail = FALSE)\" or equivalently \"qnorm(alpha, lower.tail = TRUE)\". Please run the next two cells to see these quantiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnorm(.05, lower.tail = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-qnorm(.05, lower.tail = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you**. Now can you please explain where the rejection region is. It should be to the left or right of some $z$ values from the standard normal distribution. Please answer below in a new cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you.** Given the rejection region you have found and the observed test statistic, what is the conclusion of this hypothesis test? Please explain below in a new cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to determine the level of significance, or p-value, of this test. If our rejection region was left tailed we would look for $P(Z \\leq B^*)$ by using \"pnorm(BStar, lower.tail = TRUE)\". If our rejection region was right tailed we would look for $P(Z \\geq B^*)$ using \"pnorm(BStar, lower.tail = FALSE)\". Both probabilities are found in the next two cells (but you only need one). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnorm(BStar, lower.tail = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnorm(BStar, lower.tail = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question for you** Given the two probabilities above, which one is the correct p-value? Please answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, we can use R to do the entire test in one step. This is included below. Please remember that if we specify an \"alternative\", R will compute a different type of confidence interval than what we use in this class. So to get the type of confidence interval we use, you would not specify an alternative. Since we are doing a hypotheis test here, we need to say what the alternative hypotheis is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SignTest(MetroCommutes$Time, alternative = \"less\", mu = 25.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Your turn (the training wheels are off) \n",
    "Now, let's analyze the other variable in the dataset on commuting patterns. This variable is called \"Distance\" and it is the distance that each survey respondent travels to get to work. \n",
    "\n",
    "## 2.1) A \"Q-Q plot\" for Distance traveled to work\n",
    "First please make a Q-Q plot for the \"Distance\" variable. Before we used the function \"qqnorm\" like this: \"qqnorm(MetroCommutes$Time, frame = FALSE)\". Please insert a new code cell below and repeat the process for the \"Distance\" variable. Then please comment on whether you think this variable is normally distributed (insert a new cell below the picture, change to markdown, and comment). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) A boxplot for Distance traveled to work\n",
    "Now below please make a boxplot for the \"Distance\" variable. You should be able to use the \"boxplot\" function but will need to do \"boxplot(dataset$variable)\", where you change the \"dataset\" and \"variable\" to what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) A hypothesis test regarding distance traveled to work\n",
    "Now, let's determine if there is evidence that the median distance traveled to work is greater than 10 miles. Let's test hypotheses with $\\alpha = .05$. Please use the \"SignTest\" function to do this. Earlier you did \"SignTest(MetroCommutes$Time, alternative = \"less\", mu = 25.25)\"; you should be able to modify this code to match your testing setup. Once you have conducted the hypothesis test, please insert a new cell below it (a markdown cell) and comment on your results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
