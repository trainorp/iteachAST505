\documentclass[xcolor=dvipsnames]{beamer} 
\usetheme{AnnArbor}
\usecolortheme{beaver}

\usepackage{amsmath,graphicx,booktabs,tikz,subfig,color,lmodern}
\definecolor{mycol}{rgb}{.4,.85,1}
\setbeamercolor{title}{bg=mycol,fg=black} 
\setbeamercolor{palette primary}{use=structure,fg=white,bg=red}
\setbeamercolor{block title}{fg=white,bg=red!50!black}
% \setbeamercolor{block title}{fg=white,bg=blue!75!black}

\title[Lecture 10]{Lecture 10: Inferences about differences in means and paired samples}
\author[Patrick Trainor]{Patrick Trainor, PhD, MS, MA}
\institute[NMSU]{New Mexico State University}
\date{September 25, 2019}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}{Outline}
\tableofcontents[hideallsubsections]
\end{frame}

\begin{frame}{Introduction}
	\begin{itemize}
		\item In the last two lectures we discussed:
		\begin{itemize}
			\item Estimating the population mean (or median) for one population
			\item Testing hypotheses regarding the value of the population mean (or median) for one population
		\end{itemize}
	\item[]
	\item Now we want to discuss comparing means between two groups!
	\item[]
	\item Examples:
	\begin{itemize}
		\item Are cancer cells less viable after treatment with a new drug? 
			\begin{itemize}
				\item Group A: cells not treated with the drug
				\item Group B: cells treated with the drug
			\end{itemize}
		\item Are stress levels lower in Marines who participate in guided meditation (this was actually studied)?
			\begin{itemize}
				\item Group A: Marines who were required to participate in meditation
				\item Group B: Marines who were not required to participate in meditation
			\end{itemize}
	\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Independence of samples / Independence of measurements within samples}
	\begin{itemize}
		\item In this lecture we will talk a lot about ``independent samples'' versus ``dependent samples''. What is the difference?	
		\item[]
		\item Dependent sample examples:
		\begin{itemize}
			\item Testing the effect of a drug / therapeutic / treatment / intervention using the same experimental subjects by sampling before and after intervention
			\item Sampling with a geographic / spatial component
			\item Sampling with a temporal component 
			\item[]
		\end{itemize}
		\item Statistical procedures (hypothesis tests, interval estimation) that require the independence of measurements in a sample or between samples break down if they aren't truly independent
	\end{itemize}
\end{frame}

\section{Inferences about $\mu_1 - \mu_2$: Independent Samples}
\subsection{Confidence intervals given equal population variances}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Both populations are normally distributed and $\sigma_1 = \sigma_2$}
	\begin{itemize}
		\item The first case we will discuss is for when we have measurements from two groups (populations), the measurements are normally distributed, and the variance (or standard deviation) is the same in both groups
		\item[]
		\item The point estimate for the difference in means: $\bar{y}_1 - \bar{y}_2$
		\item[]
		\item Confidence interval for a given $\alpha$:
		\begin{gather*}
			(\bar{y}_1 - \bar{y}_2) \pm t_{1-\alpha /2} \times s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}} \quad \text{where:} \\
			s_p = \sqrt{\frac{(n_1 -1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 -2}} \quad \text{and} \quad \text{df} = n_1 + n_2 -2
		\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{Both populations are normally distributed and $\sigma_1 = \sigma_2$}{Example}
\begin{columns}
	\begin{column}{.5 \textwidth}
		\begin{itemize}
			\item You have genetically modified a strain of rice to express a different variant in a gene of interest 
			\item[]
			\item You want to estimate the difference in root dry mass with a 90\% confidence interval
			\item[]
			\item You measure the root dry mass of ten wild type plants and 10 with the new variant
		\end{itemize}
	\end{column}
	\begin{column}{.5 \textwidth}
		\begin{center}
			\includegraphics[width=.7 \linewidth]{rice1}
		\end{center}
	\end{column}
\end{columns}
\end{frame}

\begin{frame}{Both populations are normally distributed and $\sigma_1 = \sigma_2$}{Example}
\begin{itemize}
	\item The point estimate for the difference in means: $\bar{y}_1-\bar{y}_2 = 12.609-9.798 = 2.811$
	\item[]
	\item We need to estimate the standard deviation of the difference:
	\begin{align*}
	s_p = \sqrt{\frac{(n_1 -1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 -2}} = \sqrt{\frac{(9)2.959^2 + (9)2.599^2}{18}} = 2.785
	\end{align*}
	\item The 90\% confidence interval is then: 
	\begin{align*}
	(\bar{y}_1 - \bar{y}_2) \pm t_{1-\alpha /2, n_1 + n_2 - 2} \times s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}\\
		2.811 \pm t_{0.95, 18} 2.785 \sqrt{\frac{1}{10} + \frac{1}{10}} = (0.651, 4.971)
	\end{align*}
\end{itemize}127.400 - 109.750 - 0
\end{frame}

\subsection{Hypothesis testing given equal population variances}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Tests of $\mu_1 - \mu_2$ assuming equal variances and normal dist.}
\begin{itemize}
	\item If we have two population distributions that are normal with equal variances, and the samples from each are independent, then we can test for a difference in population means: $\mu_1 - \mu_2$. 
	
	\begin{itemize}
		\item For these tests we specify a null difference value, $D_0$
		\item $D_0 = 0$ means our null hypothesis is no difference between the two groups (populations)
		\item[]
	\end{itemize}
	\item Hypotheses:
	\begin{itemize}
		\item Case 1. $H_0: \mu_1 - \mu_2 \leq D_0$ vs. $H_a: \mu_1 - \mu_2 > D_0$
		\item Case 2. $H_0: \mu_1 - \mu_2 \geq D_0$ vs. $H_a: \mu_1 - \mu_2 < D_0$
		\item Case 3. $H_0: \mu_1 - \mu_2 = D_0$ vs. $H_a: \mu_1 - \mu_2 \neq D_0$
		\item[]
	\end{itemize}
	\item Test statistic:
	\begin{align*}
	t^* = \frac{(\bar{y}_1-\bar{y}_2) - D_0}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
	\end{align*}
\end{itemize}
\end{frame}

\begin{frame}{Tests of $\mu_1 - \mu_2$ assuming equal variances and normal dist.}
\begin{itemize}
	\item Hypotheses:
	\begin{itemize}
		\item Case 1. $H_0: \mu_1 - \mu_2 \leq D_0$ vs. $H_a: \mu_1 - \mu_2 > D_0$
		\item Case 2. $H_0: \mu_1 - \mu_2 \geq D_0$ vs. $H_a: \mu_1 - \mu_2 < D_0$
		\item Case 3. $H_0: \mu_1 - \mu_2 = D_0$ vs. $H_a: \mu_1 - \mu_2 \neq D_0$
		\item[]
	\end{itemize}
	
	\item Test statistic:
	\begin{align*}
	t^* = \frac{(\bar{y}_1-\bar{y}_2) - D_0}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
	\end{align*}
	
	\item Rejection region / rule:
	\begin{itemize}
		\item Case 1. Reject $H_0$ if $t^* \geq t_{1-\alpha, \text{df} = n_1 + n_2 -2}$ with level of significance, $p\text{-value}=P(t \geq t^*)$
		\item Case 2. Reject $H_0$ if $t^* \leq t_{\alpha, \text{df} = n_1 + n_2 -2}$ with $p\text{-value}=P(t \leq t^*)$
		\item Case 3. Reject $H_0$ if $|t^*| \geq t_{1-\alpha / 2, \text{df} = n_1 + n_2 -2}$ with $p\text{-value}=2 \times P(t \geq |t^*|)$
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Tests of $\mu_1 - \mu_2$ assuming equal variances and normal dist.}{Example}
\begin{itemize}
	\item The following data comes from: Immer, F.R., Hayes, H.D. \& LeRoy Powers. (1934) ``Statistical determination of barley varietal adaptation''. \emph{Journal of the American Society for Agronomy, 26}.
	\item[]
	\item You want to test whether the ``trebi'' variety of barley has a higher yield than the ``velvet'' variety. You observe the following data from 1931 yields with $n=6$ per variety: $\bar{y}_{\text{trebi}} = 127.400$, $\bar{y}_{\text{velvet}} = 103.467$, $s_{\text{trebi}} = 36.671$, $s_{\text{velvet}} = 32.647$. Conduct statisitcal tests at $\alpha = 0.025$ (suppose that for some reason if you falsely reject the null hypothesis it will be extra bad)
\end{itemize}
\end{frame}

\begin{frame}{Tests of $\mu_1 - \mu_2$ assuming equal variances and normal dist.}{Example}
\begin{itemize}
	\item We want to test $H_0: \mu_{\text{trebi}} - \mu_{\text{velvet}} \geq 0$ versus $H_a: \mu_{\text{trebi}} - \mu_{\text{velvet}} < 0$. Our rejection rule is Reject $H_0$ if $t \geq t_{1-\alpha, \text{df} = n_1 + n_2 -2}$
	\item[]
	\item To compute our test statistic we will need an estimate of the variance of the difference
	\begin{align*}
		s_p &= \sqrt{\frac{(n_1 -1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 -2}} \\
		&= \sqrt{\frac{(5)(36.671^2) + (5)(32.647^2)}{10}} \\
		&= 34.717
	\end{align*}
\end{itemize}
\end{frame}

\begin{frame}{Tests of $\mu_1 - \mu_2$ assuming equal variances and normal dist.}{Example}
\begin{itemize}
	\item We want to test $H_0: \mu_{\text{trebi}} - \mu_{\text{velvet}} \geq 0$ versus $H_a: \mu_{\text{trebi}} - \mu_{\text{velvet}} < 0$. Our rejection rule is Reject $H_0$ if $t^* \geq t_{1-\alpha, \text{df} = n_1 + n_2 -2}$
	\item[]
	\item Our test statistic is:
	\begin{align*}
	t^* &= \frac{(\bar{y}_1-\bar{y}_2) - D_0}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} = \frac{(127.400 - 103.467 - 0)}{34.717 \sqrt{\frac{1}{6}+\frac{1}{6}}} = 1.194
	\end{align*}
	\item Our critical value is $t_{0.975,10} = 2.228$, so we fail to reject the null hypothesis. Although $\bar{y}_{\text{trebi}} - \bar{y}_{\text{velvet}} = 23.933$ we do not have strong enough evidence to conclude that ``trebi'' yields are higher than ``velvet'' at $\alpha = 0.025$
\end{itemize}
\end{frame}

\begin{frame}{Tests of $\mu_1 - \mu_2$ assuming equal variances and normal dist.}{Example}
\begin{itemize}
	\item What is the level of significance for the previous example
	\begin{align*}
		p\text{-value}=P(t_{\text{df} = 10} \geq t^*) = P(t_{\text{df} = 10} \geq 1.194) = 0.13
	\end{align*}
	\item[]
	\item Question: What Type I error (rejecting the null hypothesis when it is in fact true) probability would we have had to accept (prior to testing) in order to reject the null hypothesis?
	\begin{itemize}
		\item $\alpha > 0.13$
		\item[]
	\end{itemize}
	\item Would $\alpha = 0.14$ be an acceptable Type I error probability to you?
\end{itemize}
\end{frame}

\subsection{Confidence intervals given unequal population variances}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Unequal population variances}
	\begin{itemize}
		\item When we have normally distributed data from two groups (populations) but these have different variances and we want to construct confidence intervals for $\mu_1 -\mu_2$ we need to adjust:
		\begin{itemize}
			\item The degrees of freedom (which specifies our $t$-distribution)
			\item[]
			\item The formula for estimating the standard deviation of the difference between population means

		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{CI for $\mu_1-\mu_2$ given unequal variances}
	\begin{itemize}
		\item We first calculate $c$:
		\begin{align*}
		c = \frac{s_1^2 / n_1}{s_1^2 / n_1 + s_2^2/n_2}
		\end{align*}
		Then we have an updated formula (known as the \textbf{\emph{Welch-Satterthwaite approximation}}) for the degrees of freedom:
		\begin{align*}
		df = \frac{(n_1 -1)(n_2-1)}{(1-c)^2(n_1-1)+c^2(n_2-1)}
		\end{align*}
		\item Formula:
		\begin{align*}
			(\bar{y}_1-\bar{y}_2) \pm t_{1-\alpha / 2, df} \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}
		\end{align*}
	\end{itemize}
\end{frame}

\subsection{Hypothesis testing given unequal population variances}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Tests of $\mu_1 - \mu_2$ assuming $\neq$ variances and normal dist.}
\begin{itemize}
\item Hypotheses:
\begin{itemize}
	\item Case 1. $H_0: \mu_1 - \mu_2 \leq D_0$ vs. $H_a: \mu_1 - \mu_2 > D_0$
	\item Case 2. $H_0: \mu_1 - \mu_2 \geq D_0$ vs. $H_a: \mu_1 - \mu_2 < D_0$
	\item Case 3. $H_0: \mu_1 - \mu_2 = D_0$ vs. $H_a: \mu_1 - \mu_2 \neq D_0$
	\item[]
\end{itemize}
\item Test statistic:
\begin{align*}
t^* = \frac{(\bar{y}_1-\bar{y}_2)-D_0}{\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}}
\end{align*}
\item Rejection region / rule:
\begin{itemize}
	\item Case 1. Reject $H_0$ if $t^* \geq t_{1-\alpha, \text{df}}$ with level of significance, $p\text{-value}=P(t \geq t^*)$
	\item Case 2. Reject $H_0$ if $t^* \leq t_{\alpha, \text{df} }$ with $p\text{-value}=P(t \leq t^*)$
	\item Case 3. Reject $H_0$ if $|t^*| \geq t_{1-\alpha / 2, \text{df}}$ with $p\text{-value}=2 \times P(t \geq |t^*|)$
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Unequal variances example}{Part 1}
	\begin{itemize}
		\item There are 5 types of myocardial infarction (heart attack). You are interested in whether platelet counts (measured in thousands per $\mu$L) differ between two of the types (Type 1: thrombotic MI and Type 2: non-thrombotic MI). You observe the following data from 11 Type 1 MI's and 12 Type 2 MI's: $\bar{y}_{\text{Type 1}}=189.427$, $\bar{y}_{\text{Type 2}}=217.583$, $s_{\text{Type 1}} = 80.095$, and $s_{\text{Type 2}} = 64.945$. Test for a difference between the two types in platelet count at $\alpha = 0.10$
		\item[]
		\item Setup:
		\begin{itemize}
			\item We will test $H_0: \mu_{\text{Type 1}} - \mu_{\text{Type 2}} =0$ versus $H_0: \mu_{\text{Type 1}} - \mu_{\text{Type 2}} \neq 0$
			\item We will reject $H_0$ if $|t^*| \geq t_{1-\alpha / 2, \text{df}}$
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Unequal variances example}{Part 1}
	\begin{itemize}
		\item The test statistic is: 
		\begin{align*}
		t^* &= \frac{(\bar{y}_1-\bar{y}_2)-D_0}{\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}} = \frac{(189.427-217.583)}{\sqrt{\frac{80.095^2}{11}+\frac{64.945^2}{12}}} = -0.921
		\end{align*}
		\item We need to calculate the degrees of freedom using the Welch-Satterthwaite approximation:
		\begin{gather*}
			c = \frac{80.095^2 / 11}{80.095^2 / 11 + 64.945^2/12} = 0.624\\
			df = \frac{(n_1 -1)(n_2-1)}{(1-c)^2(n_1-1)+c^2(n_2-1)} = \frac{10*11}{(1-0.624)^2(10) + 0.624^2 (11)} \\
			df = 19.309 \approx 19
		\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{Unequal variances example}{Part 1}
\begin{itemize}
	\item The test statistic is: 
	\begin{align*}
	t^* &= \frac{(\bar{y}_1-\bar{y}_2)-D_0}{\sqrt{\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2}}} = \frac{(189.427-217.583)}{\sqrt{\frac{80.095^2}{11}+\frac{64.945^2}{12}}} = -0.921
	\end{align*}
	\item Our critical value is then $t_{1-\alpha/2, df} = t_{0.95, 19} = 1.729$
	\item[]
	\item Since $|-0.921| = 0.921 < 1.729$ we have that $|t^*| < t_{1-\alpha / 2, \text{df}}$ and we fail to reject the null hypothesis 
	\item[]
	\item To compute the $p$-value, $2 \times P(t_{\text{df} = 19} \geq |t^*|) = 2\times P(t_{\text{df} = 19} \geq 0.921) = 0.369$
\end{itemize}
\end{frame}

\begin{frame}{Unequal variances example}{Part 1}
\begin{itemize}
	\item There are 5 types of myocardial infarction (heart attack). You are interested in whether platelet counts (measured in thousands per $\mu$L) differ between two of the types (Type 1: thrombotic MI and Type 2: non-thrombotic MI). You observe the following data from 11 Type 1 MI's and 12 Type 2 MI's: $\bar{y}_{\text{Type 1}}=189.427$, $\bar{y}_{\text{Type 2}}=217.583$, $s_{\text{Type 1}} = 80.095$, and $s_{\text{Type 2}} = 64.945$. Determine a 95\% confidence interval for the difference in platelet count means between the two types
	\item[] LOH
	\item Setup:
	\begin{itemize}
		\item We will test $H_0: \mu_{\text{Type 1}} - \mu_{\text{Type 2}} =0$ versus $H_0: \mu_{\text{Type 1}} - \mu_{\text{Type 2}} \neq 0$
		\item We will reject $H_0$ if $|t^*| \geq t_{1-\alpha / 2, \text{df}}$
	\end{itemize}
\end{itemize}
\end{frame}

\section{Inferences about $\mu_1 - \mu_2$: Paired Samples}
\subsection{Confidence intervals}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\subsection{Hypothesis testing}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\end{document}