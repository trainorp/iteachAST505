\documentclass[xcolor=dvipsnames]{beamer} 
\usetheme{AnnArbor}
\usecolortheme{beaver}

\usepackage{amsmath,graphicx,booktabs,tikz,subfig,color,lmodern}
\definecolor{mycol}{rgb}{.4,.85,1}
\setbeamercolor{title}{bg=mycol,fg=black} 
\setbeamercolor{palette primary}{use=structure,fg=white,bg=red}
\setbeamercolor{block title}{fg=white,bg=red!50!black}
% \setbeamercolor{block title}{fg=white,bg=blue!75!black}

\title[Lecture 14]{Lecture 14: Analysis of Variance}
\author[Patrick Trainor]{Patrick Trainor, PhD, MS, MA}
\institute[NMSU]{New Mexico State University}
\date{October}

\begin{document}
	
\begin{frame}
	\maketitle
\end{frame}

\begin{frame}{Outline}
	\tableofcontents[hideallsubsections]
\end{frame}

\section{Introduction}

\begin{frame}{Outline}
	\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Introduction}
	\begin{center}
		\includegraphics[width=.9\linewidth]{Trees1}
	\end{center}
\end{frame}

\begin{frame}{Introduction}
	\begin{center}
		\includegraphics[width=.9\linewidth]{Trees2}
	\end{center}
\end{frame}

\begin{frame}{Introduction}
	\begin{itemize}
		\item \textbf{Within-group (sample) variation:} Variability of individual measurements that are all from one group (sample). 
		\begin{itemize}
			\item Not all of the measurements from one group will be equal to the mean in that group
			\item This type of variation may be related to the independent variable
		\end{itemize}
		\item[]
		\item \textbf{Between-group (sample) variation:} Variability between separate groups of interest. 
		\begin{itemize}
			\item Not all of the means for each group will be identical
			\item This type of variation may be related to the independent variable
		\end{itemize}
		\item[]
		\item When the between-group variation is large relative to the within-group variation we have evidence that population means are different 
	\end{itemize}
\end{frame}

\begin{frame}{Introduction}
	\begin{center}
		\includegraphics[width=.9\linewidth]{Trees1b}
	\end{center}
\end{frame}

\begin{frame}{Introduction}
	\begin{center}
		\includegraphics[width=.9\linewidth]{Trees2b}
	\end{center}
\end{frame}

\begin{frame}{Introduction}
	\begin{center}
		\includegraphics[width=1\linewidth]{Trees3}
	\end{center}
\end{frame}

\begin{frame}{Introduction}
	\begin{itemize}
		\item \textbf{Analysis of Variance:} ``All differences in sample means are judged statistically
		significant (or not) by comparing them to the variation within samples''
		\item[]
		\item ``Analysis of Variance'' (ANOVA) is not about comparing population variances between multiple groups
		\item[]
		\item In general if we have $p$ groups, we want to test the hypotheses:
		\begin{itemize}
			\item $H_0: \mu_1 = \mu_2 = \hdots = \mu_p$
			\item $H_a: $ At least one of the means, say $\mu_j$ ($j$ denotes a specific group), is not equal to the rest 
			\item[]
		\end{itemize}
		\item We cannot use pairwise $t$-tests for more than 2 groups because the true Type I error rates will be much greater than specified
	\end{itemize}
\end{frame}

\section{The ANOVA framework}

\begin{frame}{Outline}
	\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{If $H_0$ were true}
	\begin{itemize}
		\item To develop a test of $H_a$ vs $H_0$, we need to determine a test statistic and determine the distribution of the test statistic if the null hypothesis were true. For this we will assume:
		\begin{enumerate}
			\item Each of the $p$ groups (populations) has a normal distribution
			\item[]
			\item The variances of the $p$ groups (populations) are equal
			\item[]
			\item The measurements for each group $j$ is an independent random samples from their respective populations
			\item[]
		\end{enumerate}
	\item Now we can measure variability using two measures:
	\begin{itemize}
		\item $s_W^2$: Within-group variance 
		\item[]
		\item $s_B^2$: Between-group variance 
	\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{If $H_0$ were true}
	\begin{itemize}
		\item $s_W^2$: Within-group variance 
		\begin{itemize}
			\item If the null hypothesis were true, then each group would have the same population variance about the same population mean
			\item[]
			\item So then we could estimate this population variance using each sample (from each different group) as:
			\begin{gather*}
				s_W^2 = \frac{\sum_{j=1}^p (n_j -1) s_j^2}{\sum_{j=1}^p (n_j - 1)}
			\end{gather*}
			\item Notice that we have seen this before in $t$-tests that assumed equal variances. In this case $p=2$, and:
			\begin{gather*}
			s_W^2 = \frac{\sum_{j=1}^p (n_j -1) s_j^2}{\sum_{j=1}^p (n_j - 1)} = \frac{(n_1-1) s_1^2 + (n_2 -1) s_2^2}{n_1 + n_2 -2}
			\end{gather*}
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{If $H_0$ were true}
	\begin{itemize}
		\item $s_B^2$: Between-group variance 
		\begin{itemize}
			\item If $H_0$ were true, than the sample mean  $\bar{y}_j$ of each of the independent samples from the $p$ groups would be an estimate of the same population mean because $\mu_1 = \mu_2 = \hdots = \mu_p$
			\item[]
			\item We could then compute the sample variance of this set of $p$ sample means: $\{\bar{y}_1, \bar{y}_2, \hdots \bar{y}_p\}$:
			\begin{gather*}
				\frac{\sum_{j=1}^p (\bar{y}_j - \bar{y}.)^2}{p-1}
			\end{gather*}
			where $\bar{y}. = \frac{\sum_{j=1}^p \bar{y}_j}{p}$
			\item[]
			\item If $n_j$ is equal for each group, then the above quantity is an estimate of $\sigma^2 / n$. So $n_j$ times that quantity estimates $\sigma^2$
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{If $H_0$ were true}
	\begin{itemize}
		\item Now a test statistic!
		\item[]
		\item If the null hypothesis is true, then $s_B^2$ and $s_W^2$ both estimate $\sigma^2$ and should both be close to eachother, so:
		\begin{gather*}
		F^* = s_B^2 / s_W^2
		\end{gather*}
		Should be close to 1 and has an $F$ distribution
	\end{itemize}
\end{frame}

\begin{frame}{If $H_0$ was not true}
	\begin{itemize}
		\item If $H_0$ were not true then we would expect that $s^2_B$ will be greater than $s_W^2$. That is, the between group variability will be greater than the within group variability 
		\item[]
		\item So this would put our test statistic $F^*$ in the right tail of the $F$ distribution under the null
		\item[]
		\item We will call this testing Analysis of Variance (or ANOVA or AOV)
	\end{itemize}
\end{frame}

\begin{frame}{Break for data}
	\begin{center}
		\includegraphics[width=.9\linewidth]{Trees1}
	\end{center}
\end{frame}

\begin{frame}{Break for data}
	\begin{itemize}
		\item Before we introduce some notation and the process for doing an ANOVA $F$-test let's introduce some data
	\end{itemize}
\begin{center}
	\includegraphics{treeData2}
\end{center}
\end{frame}

\begin{frame}{Break for data}
	\begin{center}
		\includegraphics[width=.45 \linewidth]{treeData}
	\end{center}
\end{frame}

\begin{frame}{Completely randomized designs}
	\begin{itemize}
		\item We will now talk about completely randomized designs. In a completely randomized design we have multiple populations whose means we want to compare, and we have a random sample of observations from each
	\end{itemize}
\end{frame}

\begin{frame}{Notation}
	\begin{itemize}
		\item $k$: The number of groups (populations)
		\item[]
		\item $y_{j,i}:$ The $i$th sample observation from the group (population) $j$. For example, $y_{3,2}$ in our data would be the dbh of Shortleaf Pine \#2
		\item[]
		\item $n_j$: The number of observations from group (population) $j$. For our data $n_j=10$ for all groups $j$
		\item[]
		\item $N$: The total sample size. That is $N = \sum_{j=1}^{k} n_j$. For our data $N = 30$
		\item[]
		\item $\bar{y}_{j.}$: The mean of the $n_j$ observations from group (population) $j$. That is $\bar{y}_{j.} = \frac{\sum_{i = 1}^{n_j} y_{j,i}}  {n_j}$
		\item[]
		\item $\bar{y}_{..}$: The mean of all of the observations $\sum_{j=1}^k\sum_{i = 1}^{n_j} y_{j,i} / n_j$
	\end{itemize}
\end{frame}

\begin{frame}{Sum of squares}{Total sum of squares (TSS)}
	\begin{itemize}
		\item We are now going to introduce how $s^2_B$, $s^2_W$, and the ANOVA $F$ test statistic are computed in practice 
		\item[]
		\item \textbf{Total sum of squares (TSS).} The total sum of squares is the variability of the sample measurements about the overall mean (of all measurements):
		\begin{gather*}
			\text{TSS} = \sum_{j=1}^{k} \sum_{i = 1}^{n_j}\left(y_{j,i} - \bar{y}_{..}\right)^2
		\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{Sum of squares}{Partitioning TSS}
	\begin{itemize}
		\item We can partition the TSS as follows:
		\begin{gather*}
			\sum_{j=1}^{k} \sum_{i = 1}^{n_j}\left(y_{j,i} - \bar{y}_{..}\right)^2 = \sum_{j=1}^{k}\sum_{i = 1}^{n_j} (y_{j,i}-\bar{y}_{j.})^2 + \sum_{j=1}^k n_j (\bar{y}_{j.} - \bar{y}_{..})^2
		\end{gather*}
		\item[]
		\item This is:
		\begin{gather*}
			\text{TSS} =\sum_{j=1}^{k} \sum_{i = 1}^{n_j}\left(y_{j,i} - \bar{y}_{..}\right)^2 = \text{SSW} + \text{SSB}
		\end{gather*}
		if $\text{SSW} = \sum_{j=1}^{k}\sum_{i = 1}^{n_j} (y_{j,i}-\bar{y}_{j.})^2$ and $\text{SSB}= \sum_{j=1}^k n_j (\bar{y}_{j.} - \bar{y}_{..})^2$
	\end{itemize}
\end{frame}

\begin{frame}{Sum of Squares}{Within-sample sum of squares}
	\begin{itemize}
		\item \textbf{Within-sample sum of squares (SSW).} A measure of within-sample variability:
		\begin{gather*}
			\text{SSW} = \sum_{j=1}^{k}\sum_{i = 1}^{n_j} (y_{j,i}-\bar{y}_{j.})^2 = (n_1-1)s_1^2 + (n_2-1)s_2^2 + \hdots + (n_k-1)s_k^2
		\end{gather*}
		\item \textbf{Sum of squares between samples (SSB).} A measure of variability between (or among) the sample means:
		\begin{align*}
			\text{SSB} =\sum_{j=1}^k n_j (\bar{y}_{j.} - \bar{y}_{..})^2 = n_1 (\bar{y}_{1.}-\bar{y}_{..})^2 + &n_2 (\bar{y}_{2.}-\bar{y}_{..})^2 + \hdots + \\ &n_k (\bar{y}_{k.}-\bar{y}_{..})^2
		\end{align*}
	\end{itemize}
\end{frame}

\begin{frame}{Mean squares}
	\begin{itemize}
		\item The quantities $s^2_B$ and $s^2_W$ are (historically) referred to as mean squares (as in mean square between samples and mean square within samples, respectively):
		\begin{gather*}
			s^2_B = \frac{\text{SSB}}{k-1} \quad \quad s^2_W = \frac{\text{SSW}}{N-k}
		\end{gather*}
		where $k-1$ is the degrees of freedom of $s^2_B$ and $N-k$ is the degrees of freedom of $s^2_W$
	\end{itemize}
\end{frame}

\begin{frame}{Process for An Analysis of Variance (ANOVA)}
	\begin{itemize}
		\item The process:
		\begin{enumerate}
			\item Compute the partitioning of TSS into SSB and SSW
			\item Determine the number of degrees of freedom for each
			\item Compute the mean squares $s_B^2$ and $s_W^2$ by dividing SSB and SSW by their sum of squares
			\item Determine the test statistic: $F^* = s_B^2 / s_W^2$
			\item We will reject the null hypothesis (that all means are equal) if: $F^* > F_{\alpha, k-1, N-k}$
			\item[]
		\end{enumerate}
	\item The ANOVA table will help us organize these steps:
	\vspace{2mm}
	\begin{center}
		{\scriptsize
		\begin{tabular}{lp{1.2cm}cp{2.5cm}c}
			\hline 
			\textbf{Source of Variation} & \textbf{Sum of Squares} & \textbf{df} & \textbf{Mean Square} & $F$-\textbf{Test} \\ \hline 
			Between samples & SSB & $k - 1$ & $s_B^2 = \text{SSB} / (k-1)$ & $F^* = s_B^2 / s_W^2$ \\
			Within samples & SSW & $N - k$ &  $s_W^2 = \text{SSW} / (N-k)$ & \\
			Total & TSS & $N-1$ & & \\ \hline
		\end{tabular}}
	\end{center}
	\end{itemize}
\end{frame}

\section{$F$-test Examples}
\subsection{Difference in mean dbh in pine trees}

\begin{frame}{Outline}
	\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{The data}
	\begin{center}
		\includegraphics[width=.9\linewidth]{Trees1}
	\end{center}
\end{frame}

\begin{frame}{Example \#1}{Research Question}
	\begin{itemize}
		\item \textbf{Example \# 1:} Determine if there is evidence that at least one of the populations of pine trees has different dbh than the others ($\alpha = .05$)
		\item[]
		\item Formally:
		\begin{itemize}
			\item $H_0: \mu_1 = \mu_2 = \mu_3$
			\item $H_a:$ At least one of the population means differs from the rest
			\item[]
		\end{itemize}
		\item Rejection rule: We will reject $H_0$ if $F^* > F_{\alpha, k-1, N-k}$
			\vspace{2mm}
		\begin{center}
			{\scriptsize
				\begin{tabular}{lp{1.2cm}cp{2.5cm}c}
					\hline 
					\textbf{Source of Variation} & \textbf{Sum of Squares} & \textbf{df} & \textbf{Mean Square} & $F$-\textbf{Test} \\ \hline 
					Between samples & SSB & $k - 1$ & $s_B^2 = \text{SSB} / (k-1)$ & $F^* = s_B^2 / s_W^2$ \\
					Within samples & SSW & $N - k$ &  $s_W^2 = \text{SSW} / (N-k)$ & \\
					Total & TSS & $N-1$ & & \\ \hline
			\end{tabular}}
		\end{center}
	\end{itemize}
\end{frame}

\begin{frame}{Example \#1}{SSB}
	\begin{itemize}
		\item To compute SSB we need to know the overall ``grand'' mean and the mean in each group:
		\begin{center}
			\begin{tabular}{|c|c|c|c|}
				\hline
				\textbf{Population \#} & \textbf{Population} & $n$ & \textbf{Mean} \\
				\hline \hline
				1  & Eastern White Pine    &   10 &  15.165 \\ \hline 
				2 &  Sand Pine              & 10 &    9.523\\ \hline 
				3 &  Shortleaf Pine        &  10 &   13.765\\ \hline \hline
				\textbf{Overall} & & 30 & 12.818 \\ \hline
			\end{tabular}
		\end{center}
				\vspace{2mm}
		\item So SSB is:
		\begin{gather*}
		\sum_{j=1}^3 n_j (\bar{y}_{j.} - \bar{y}_{..})^2 = n_1 (\bar{y}_{1.}-\bar{y}_{..})^2 + n_2 (\bar{y}_{2.}-\bar{y}_{..})^2 + n_3 (\bar{y}_{3.}-\bar{y}_{..})^2 =  \\
		 10(15.165 - 12.818)^2 + 10(9.523-12.818)^2 + 10(13.765-12.818)^2 =\\
		 172.622
		\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{Example \#1}{SSB}
	\begin{itemize}
		\item Starting with our stock table:
		\vspace{2mm}
		\begin{center}
			{\scriptsize
				\begin{tabular}{lp{1.2cm}cp{2.5cm}c}
					\hline 
					\textbf{Source of Variation} & \textbf{Sum of Squares} & \textbf{df} & \textbf{Mean Square} & $F$-\textbf{Test} \\ \hline 
					Between samples & SSB & $k - 1$ & $s_B^2 = \text{SSB} / (k-1)$ & $F^* = s_B^2 / s_W^2$ \\
					Within samples & SSW & $N - k$ &  $s_W^2 = \text{SSW} / (N-k)$ & \\
					Total & TSS & $N-1$ & & \\ \hline
			\end{tabular}}
		\end{center}
		\vspace{5mm}
		\item We can now fill in part of the first row of the table:
			\vspace{2mm}
		\begin{center}
			{\scriptsize
				\begin{tabular}{lp{1.2cm}cp{2.5cm}c}
					\hline 
					\textbf{Source of Variation} & \textbf{Sum of Squares} & \textbf{df} & \textbf{Mean Square} & $F$-\textbf{Test} \\ \hline 
					Between samples & 172.622 & 2 & $86.311$ & $F^* = s_B^2 / s_W^2$ \\
					Within samples & SSW & $N - k$ &  $s_W^2 = \text{SSW} / (N-k)$ & \\
					Total & TSS & $N-1$ & & \\ \hline
			\end{tabular}}
		\end{center}
	\end{itemize}
\end{frame}

\begin{frame}{Example \#1}{SSW}
	\begin{itemize}
	\item To compute SSW we need to know sample variance in each group:
		\begin{center}
			\begin{tabular}{|c|c|c|c|}
				\hline
				\textbf{Population \#} & \textbf{Population} & $n$ & \textbf{Sample Variance} \\
				\hline \hline
				1  & Eastern White Pine    &   10 &  1.730 \\ \hline 
				2 &  Sand Pine              & 10 &   1.971\\ \hline 
				3 &  Shortleaf Pine        &  10 &   1.560\\ \hline 
			\end{tabular}
		\end{center}
				\vspace{2mm}
	\item So SSW is:
	\begin{gather*}
		\sum_{j=1}^{3}\sum_{i = 1}^{n_j} (y_{j,i}-\bar{y}_{j.})^2 = (n_1-1)s_1^2 + (n_2-1)s_2^2 + (n_3-1)s_3^2 =\\ 
		9(1.730)^2 + 9(1.971)^2 + 9(1.560)^2 = \\
		83.802
	\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{Example \#1}{SSB}
	\begin{itemize}
		\item Starting with last table:
		\vspace{2mm}
		\begin{center}
			{\scriptsize
				\begin{tabular}{lp{1.2cm}cp{2.5cm}c}
					\hline 
					\textbf{Source of Variation} & \textbf{Sum of Squares} & \textbf{df} & \textbf{Mean Square} & $F$-\textbf{Test} \\ \hline 
					Between samples & SSB & $k - 1$ & $s_B^2 = \text{SSB} / (k-1)$ & $F^* = s_B^2 / s_W^2$ \\
					Within samples & SSW & $N - k$ &  $s_W^2 = \text{SSW} / (N-k)$ & \\
					Total & TSS & $N-1$ & & \\ \hline
			\end{tabular}}
		\end{center}
		\vspace{5mm}
		\item We can now fill in the next row of the table and determine $F^*$:
		\vspace{2mm}
		\begin{center}
			{\scriptsize
				\begin{tabular}{lp{1.2cm}cp{2.5cm}c}
					\hline 
					\textbf{Source of Variation} & \textbf{Sum of Squares} & \textbf{df} & \textbf{Mean Square} & $F$-\textbf{Test} \\ \hline 
					Between samples & 172.622 & 2 & 86.311 & $F^*=27.815$ \\
					Within samples & 83.802 & 27 &  3.103 & \\
					Total & TSS & $N-1$ & & \\ \hline
			\end{tabular}}
		\end{center}
	\end{itemize}
\end{frame}

\begin{frame}{Example \#1}{TSS}
	\begin{itemize}
		\item We already have enough to conduct our hypothesis test, but for completeness we will fill in TSS
		\item[]
		\item TSS is the squared deviation of every observation from the overall or ``grand'' mean:
		\begin{gather*}
		\text{TSS} = \sum_{j=1}^{k} \sum_{i = 1}^{n_j}\left(y_{j,i} - \bar{y}_{..}\right)^2 = \sum_{j=1}^{k} \sum_{i = 1}^{n_j}\left(y_{j,i} - 12.818\right)^2 = \\
		(12.25 - 12.818)^2 + (7.31 - 12.818)^2 + (13.38 - 12.818)^2 + \\(13.87 - 12.818)^2 + \hdots + (8.82 - 12.818)^2 + (17.83 - 12.818)^2 =\\
		256.424
		\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{Example \#1}{SSB}
	\begin{itemize}
		\item Our table is then complete:
		\vspace{2mm}
		\begin{center}
			{\scriptsize
				\begin{tabular}{lp{1.2cm}cp{2.5cm}c}
					\hline 
					\textbf{Source of Variation} & \textbf{Sum of Squares} & \textbf{df} & \textbf{Mean Square} & $F$-\textbf{Test} \\ \hline 
					Between samples & 172.622 & 2 & 86.311 & $F^*=27.815$ \\
					Within samples & 83.802 & 27 &  3.103 & \\
					Total & 256.424 & 29 & & \\ \hline
			\end{tabular}}
		\end{center}
	\vspace{2mm}
	\item Now for our hypothesis testing
	\item[]
	\item RR: Reject $H_0$ if $F^* > F_{\alpha, k-1, N-k} = F_{0.05, 2, 27} =3.354 $
	\item[]
	\item Conclusion: Since $27.815 > 3.354$ we reject the null hypothesis. There is evidence at least one of the population means is different than the others. 
	\end{itemize}
\end{frame}

\subsection{HPV Viral oncogenes}

\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\section{Multiple comparisons}

\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Post-hoc tests}
	\begin{itemize}
		\item If you have rejected your null hypothesis in the ANOVA, then you have evidence that not all the population means are the same. But which ones are different?
		\item[]
		\item Unplanned testing of differences between means \emph{after} determining that our ANOVA $F$-test is significant is called \textbf{post-hoc testing}
		\item[]
		\item Naive approach: Do pairwise independent samples $t$-tests for all of the possible comparisons
		\begin{itemize}
			\item So if you had three populations you would examine: $\mu_1-\mu_2$, $\mu_2-\mu_3$, and $\mu_1-\mu_3$ by independent samples $t$-tests
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Post-hoc tests}
	\begin{itemize}
		\item Naive approach: Do pairwise independent samples $t$-tests for all of the possible comparisons
		\begin{itemize}
			\item So if you had three populations you would examine: $\mu_1-\mu_2$, $\mu_2-\mu_3$, and $\mu_1-\mu_3$ by independent samples $t$-tests
			\item[]
		\end{itemize}
		\item This would be naive / bad for two reasons:
		\begin{enumerate}
			\item You have estimated the population variances when you calculated $s^2_W$ using 3 groups (re-estimating it with just two groups would be worse)
			\item[]
			\item Your probability of making a Type I error when you do the set of tests at a fixed $\alpha$ will not be $\alpha$ (it will be larger)
		\end{enumerate}
	\end{itemize}
\end{frame}

\begin{frame}{Multiple Testing}
\begin{center}
	\includegraphics[width=.8\linewidth]{sig0}
\end{center}
\end{frame}

\begin{frame}{Multiple Testing}
	\begin{center}
		\includegraphics[width=.8\linewidth]{sig1}
	\end{center}
\end{frame}

\begin{frame}{Multiple Testing}
\begin{center}
	\includegraphics[width=.8\linewidth]{sig2}
\end{center}
\end{frame}

\begin{frame}{Multiple Testing}
\begin{center}
	\includegraphics[width=.8\linewidth]{sig2}
\end{center}
\end{frame}

\begin{frame}{Multiple Testing}
\begin{center}
	\includegraphics[width=.8\linewidth]{sig3}
\end{center}
\end{frame}

\begin{frame}{Multiple Testing}
\begin{itemize}
	\item The last slides were excerpts from \emph{xkcd}: https://xkcd.com/882/
\end{itemize}
\end{frame}

\begin{frame}{Post-hoc tests}
\begin{itemize}
	\item Naive approach: Do pairwise independent samples $t$-tests for all of the possible comparisons
	\begin{itemize}
		\item So if you had three populations you would examine: $\mu_1-\mu_2$, $\mu_2-\mu_3$, and $\mu_1-\mu_3$ by independent samples $t$-tests
		\item[]
	\end{itemize}
	\item This would be naive / bad for two reasons:
	\begin{enumerate}
		\item You have estimated the population variances when you calculated $s^2_W$ using 3 groups (re-estimating it with just two groups would be worse)
		\item[]
		\item Your probability of making a Type I error when you do the set of tests at a fixed $\alpha$ will not be $\alpha$ (it will be larger)
	\end{enumerate}
\end{itemize}
\end{frame}



\begin{frame}{Post-hoc tests}{Fisher's least significant difference (LSD) method}
	\begin{itemize}
		\item The solution to our problem \#1 (we already estimated the population variances) is to use $s^2_W$ when making post-hoc comparisons
		\item[]
		\item Test statistic with $N-k$ degrees of freedom:
		\begin{gather*}
			t = \frac{\bar{y}_1 - \bar{y}_2}{\sqrt{s^2_W\left(\frac{1}{n_1}+\frac{1}{n_2}\right)}} = \frac{\bar{y}_1 - \bar{y}_2}{\sqrt{\frac{\text{SSW}}{N-k} \left(\frac{1}{n_1}+\frac{1}{n_2}\right)}}
		\end{gather*}
		\item Formula for $100(1-\alpha)\%$ confidence intervals:
		\begin{gather*}
			\bar{y}_1 - \bar{y}_2 \pm t_{\alpha / 2, N - k}{\sqrt{\frac{\text{SSW}}{N-k} \left(\frac{1}{n_1}+\frac{1}{n_2}\right)}}
		\end{gather*}
		\item This is called Fisher's least significant difference (LSD) method
	\end{itemize}
\end{frame}

\begin{frame}{Post-hoc tests}
\begin{itemize}
	\item Fisher's LSD method is superior to doing pairwise independent samples $t$-tests since it has a better estimate of the variances
	\item[]
	\item But it does not solve problem \#2
	\item[]
	\item If you conduct $m$ hypothesis tests each with a fixed $\alpha$, the probability of making at least one Type I error is: 
	\begin{gather*}
		1-(1-\alpha)^m
	\end{gather*}
	So for 1 test: 0.05, 2 tests: 0.098, 3 tests: 0.143, 10 tests: 0.401, and for 50 tests: 0.923
\end{itemize}
\end{frame}

\end{document}