\documentclass[xcolor=dvipsnames]{beamer}
\usetheme{AnnArbor}
\usecolortheme{beaver}

\usepackage{amsmath,graphicx,booktabs,tikz,subfig,color,lmodern}
\definecolor{mycol}{rgb}{.4,.85,1}
\setbeamercolor{title}{bg=mycol,fg=black} 
\setbeamercolor{palette primary}{use=structure,fg=white,bg=red}
\setbeamercolor{block title}{fg=white,bg=red!50!black}
% \setbeamercolor{block title}{fg=white,bg=blue!75!black}

\newcommand\myeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily D}}}{=}}}

\title[Lecture 17]{Lecture 17: Inference regarding several proportions}
\author[Patrick Trainor]{Patrick Trainor, PhD, MS, MA}
\institute[NMSU]{New Mexico State University}
\date{}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}{Outline}
\tableofcontents[hideallsubsections]
\end{frame}

\section{The multinomial distribution}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{The multinomial experiment}
	\begin{itemize}
		\item Earlier in the course we discussed binomial experiments that yielded binary responses (two outcomes) \pause
		\item[]
		\item Now we will discuss the case where we have experiments with 3 or more possible outcomes \pause
		\item[]
		\item Example: You conduct a poll where you ask respondents if they prefer Candidate A, Candidate B, Candidate C, or do not have a preference (4 possible outcomes)
	\end{itemize}
\end{frame}

\begin{frame}{The multinomial experiment}{Criteria for a multinomial experiment}
	\begin{itemize}
		\item Criteria for a multinomial experiment: \pause
		\begin{enumerate}
			\item The experiment consists of $n$ identical trials \pause
			\item[]
			\item Each trial results in one of $k$ outcomes \pause
			\item[]
			\item The probability that a single trial will result in an outcome $i$ is $\pi_i$ (for $i=1, 2, \hdots, p$), which remains constant from trial to trial. $\sum_{i=1}^k \pi_i = 1$ \pause
			\item[]
			\item The trials are independent \pause
			\item[]
			\item We are interested in $n_i$, the number of trials that results in outcome $i$. $\sum_{i=1}^k n_i = n$ \pause
		\end{enumerate}
	\end{itemize}
\end{frame}

\begin{frame}{The multinomial distribution}
	\begin{itemize}
		\item \textbf{The multinomial distribution}: The probability distribution for the number of observations for each of the $k$ outcomes is the multinomial distribution \pause
		\item[]
		\item The probability distribution function for the multinomial distribution function is: \pause
		\begin{gather*}
			P(n_1, n_2, \hdots, n_k) = \frac{n!}{n_1!n_2!\hdots n_k!}\pi_1^{n_1}\pi_2^{n_2}\hdots \pi_k^{n_k}
		\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{The multinomial distribution}{Example}
	\begin{itemize}
		\item A ballot initiative proposes increasing the sales tax by .5\% to fund a new library. If the percentage of residents who supports the tax is 37.5\%, with 34.5\% opposed, and 28.0\% undecided; what is the probability that in a random sample of 10 residents, 4 support the tax, 4 are opposed, and 2 are undecided? \pause
		\item[]
		\item Given the multinomial probability distribution function: \pause
		\begin{gather*}
			P(n_1, n_2, \hdots, n_k) = \frac{n!}{n_1!n_2!\hdots n_k!}\pi_1^{n_1}\pi_2^{n_2}\hdots \pi_k^{n_k} \\
			P(4, 4, 2) = \frac{10!}{4!4!2!}(0.375)^{4}(0.345)^{4}(0.280)^{2} = 0.0692
		\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{The multinomial distribution}{Expected number of outcomes}
	\begin{itemize}
		\item When we make inferences regarding multiple proportions, we will need to compute the expected number of outcomes from a multinomial distribution \pause
		\item[]
		\item \textbf{Expected number of outcomes:} To determine the expected number of outcomes from $n$ trials, we determine $E_i = n\times \pi_i$ for each outcome $i$
	\end{itemize}
\end{frame}

\begin{frame}{The multinomial distribution}{Example expected number of outcomes}
	\begin{itemize}
		\item A ballot initiative proposes increasing the sales tax by .5\% to fund a new library. If the percentage of residents who supports the tax is 37.5\%, with 34.5\% opposed, and 28.0\% undecided; what is the expected number of residents with each response from a sample of 200 voters? \pause
		\begin{itemize}
			\item Support: $200 \times 0.375 = 75$ \pause
			\item[]
			\item Oppose: $200 \times 0.345 = 69$ \pause
			\item[]
			\item Undecided: $200 \times 0.280 = 56$
		\end{itemize}
	\end{itemize}
\end{frame}

\section{Chi-Square Goodness-of-Fit Test}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Chi-Square Goodness-of-Fit Test}
	\begin{itemize}
		\item We often want to determine how likely a collection of outcomes is given specified multinomial probabilities \pause
		\item[]
		\item More specifically, if we specify a multinomial probabilities, we may want to determine the agreement between the counts of each outcome we observe versus what we would expect \pause
		\item[]
		\item The quantity:
		\begin{gather*}
			X^2 = \sum_{i=1}^k \frac{(n_i-E_i)^2}{E_i}
		\end{gather*}
		measures this agreement (or disagreement) and has a chi-squared distribution with $k-1$ degrees of freedom if the $E_i$'s are fairly large
	\end{itemize}
\end{frame}

\begin{frame}{Chi-Square Goodness-of-Fit Test}{Process}
	\begin{itemize}
		\item Hypotheses:
		\begin{itemize}
			\item $H_0: \pi_i = \pi_{i0}$ for all outcome categories $i = 1, 2, \hdots, k$. The $\pi_{i0}$ are the specified probabilities \pause
			\item $H_a: \pi_i \neq \pi_{i0}$ for at least one of the outcome categories \pause
			\item[]
		\end{itemize}
	\item Test statistic: \pause
	\begin{gather*}
		X^2 = \sum_{i=1}^k \frac{(n_i-E_i)^2}{E_i}
	\end{gather*} 
	where $n_i$ is the observed number in outcome category $i$, and $E_i=n \times \pi_{i0}$ is the expected number under $H_0$ \pause
	\item[]
	\item Rejection rule: Reject $H_0$ if $X^2 > \chi_{\alpha,\text{df}=k-1}^2$, with level of significance $P(\chi^2 > X)$
	\end{itemize}
\end{frame}

\begin{frame}{Chi-Square Goodness-of-Fit Test}{Example}
	\begin{itemize}
		\item A large sample poll was conducted in the ``East end'' neighborhoods of the city of Louisville, KY. The poll found that 57.3\% of the residents approve of the current mayor, 33.2\% do not approve of the current mayor, and 9.5\% have no opinion regarding the current mayor. You want to evaluate whether these results also generalize well to different parts of the city. You conduct a similar poll with 100 respondents each in the ``Germantown'' neighborhood and in the ``South End'' and observe the following: \pause
		\vspace{2mm}
		\begin{center}
			\begin{tabular}{ccc}
				\hline
				Response & Germantown & South End \\ \hline \hline
				Approve & 55 & 42\\
				Disapprove & 33 & 49 \\
				No opinion & 12 & 9 \\ \hline
			\end{tabular}
		\end{center}
	\end{itemize}
\end{frame}

\begin{frame}{Chi-Square Goodness-of-Fit Test}{Example}
	\begin{itemize}
		\item Are the proportions different in the Germantown neighborhood than what we have already observed? \pause
		\item[]
		\item Hypotheses:\pause
		\begin{itemize}
			\item $H_0: \pi_{\text{Approve}} = 0.573,\; \pi_{\text{Disapprove}} = 0.332,\; \pi_{\text{No opinion}}=0.095$ \pause
			\item $H_a: \pi_i \neq \pi_{i0}$ for at least one of the outcome categories \pause
			\item[]
		\end{itemize}
	\item Germantown Goodness-of-Fit test: \pause
	\vspace{1mm}
	\begin{center}
		\begin{tabular}{ccc}
			\hline
			Response & Observed & Expected \\ \hline \hline
			Approve & 55 & $100 \times 0.573 = 57.3$\\
			Disapprove & 33 & $100 \times 0.332 = 33.2$ \\
			No opinion & 12 & $100 \times 0.095 = 9.5$ \\ \hline
		\end{tabular}
	\end{center}
	\end{itemize}
\end{frame}

\begin{frame}{Chi-Square Goodness-of-Fit Test}{Example}
\begin{itemize}
	\item Hypotheses:
	\begin{itemize}
		\item $H_0: \pi_{\text{Approve}} = 0.573,\; \pi_{\text{Disapprove}} = 0.332,\; \pi_{\text{No opinion}}=0.095$
		\item $H_a: \pi_i \neq \pi_{i0}$ for at least one of the outcome categories
		\item[]
	\end{itemize}
	\item Germantown Goodness-of-Fit test:
	{\scriptsize
	\begin{center}
		\begin{tabular}{cccc}
			\hline
			Response & Observed & Expected & $\frac{(n_i-E_i)^2}{E_i}$ \\ \hline \hline
			Approve & 55 & $100 \times 0.573 = 57.3$ & $\frac{(55-57.3)^2}{57.3} = 0.09232$\\
			Disapprove & 33 & $100 \times 0.332 = 33.2$ & $\frac{(33-33.2)^2}{33.2} = 0.00120$\\
			No opinion & 12 & $100 \times 0.095 = 9.5$ & $\frac{(12-9.5)^2}{9.5}=0.65789$\\ \hline
		\end{tabular}
	\end{center}}\pause
	\vspace{1mm}
	\item Test statistic: \pause
	\begin{gather*}
	X^2 = \sum_{i=1}^k \frac{(n_i-E_i)^2}{E_i} = 0.09232 + 0.00120 + 0.65789 = 0.75141
	\end{gather*} \pause
	\item p-value: $P(\chi^2 > 0.75141) = 0.6868$
\end{itemize}
\end{frame}

\begin{frame}{Chi-Square Goodness-of-Fit Test}{Example}
	\begin{itemize}
		\item And now, is there evidence that the proportions differ in the South End neighborhoods than what we previously observed?
	\end{itemize}
\end{frame}

\begin{frame}{Chi-Square Goodness-of-Fit Test}{Example}
\begin{itemize}
	\item Hypotheses: \pause
	\begin{itemize}
		\item $H_0: \pi_{\text{Approve}} = 0.573,\; \pi_{\text{Disapprove}} = 0.332,\; \pi_{\text{No opinion}}=0.095$
		\item $H_a: \pi_i \neq \pi_{i0}$ for at least one of the outcome categories  \pause
		\item[]
	\end{itemize}
	\item ``South End'' Goodness-of-Fit test:  \pause
	{\scriptsize
		\begin{center}
			\begin{tabular}{cccc}
				\hline
				Response & Observed & Expected & $\frac{(n_i-E_i)^2}{E_i}$ \\ \hline \hline
				Approve & 42 & $100 \times 0.573 = 57.3$ & $\frac{(42-57.3)^2}{57.3} = 4.0853$\\
				Disapprove & 49 & $100 \times 0.332 = 33.2$ & $\frac{(49-33.2)^2}{33.2} = 7.5193$\\
				No opinion & 9 & $100 \times 0.095 = 9.5$ & $\frac{(9-9.5)^2}{9.5}=0.02632$\\ \hline
			\end{tabular}
	\end{center}}  \pause
	\vspace{1mm}
	\item Test statistic:  \pause
	\begin{gather*}
	X^2 = \sum_{i=1}^k \frac{(n_i-E_i)^2}{E_i} = 4.0853 + 7.5193 + 0.02632 = 11.63092
	\end{gather*} \pause
	\item p-value: $P(\chi^2 > 11.63092) = 0.00298$
\end{itemize}
\end{frame}

\begin{frame}{Chi-Square Goodness-of-Fit Test}{Note}
	\begin{itemize}
		\item The Chi-square distribution is the sampling distribution in approximation only  \pause
		\item[]
		\item It isn't always a great approximation. We should not use this test if $E_i <1$ for any $i$, or if more than 20\% of the $E_i$'s are less than 5  \pause
		\item[]
		\item If that assumption is not met there are exact tests. We don't discuss, but can be done in software
	\end{itemize}
\end{frame}

\section{$\chi^2$ test of independence}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Contingency tables}
	\begin{itemize}
		\item \textbf{Contingency tables:} When we have two categorical variables and a sample from some population, we organize the data into $r\times c$ tables called contingency tables  \pause
		\begin{itemize}
			\item $r$ is the number of rows  \pause
			\item $c$ is the number of columns  \pause
		\end{itemize}
		\item[]
		\item Example*: Visitation pasterns of 132 long-term schizophrenic patients in mental hospitals in London
		\begin{center}
			\begin{tabular}{|l|ccc|c|}
				\hline
				& \multicolumn{3}{c|}{Length of Stay (LOS)} & \\
				Visitation & 2-9 & 10-19 & 20+ & All LOS \\ \hline
				Regular & 43 & 16 & 3 & 62\\ 
				$<1/\text{month}$ & 6 & 11 & 10 & 27 \\
				Never & 9 & 18 & 16 & 43\\ \hline
				Total & 58 & 45 & 29 & 132\\ \hline
			\end{tabular}
		\end{center}
	\end{itemize}
{\tiny *J.K. Wing (1962): Institutionalism in mental hospitals. British Journal of Social Clinical Psychology}
\end{frame}

\begin{frame}{Independence / Dependence}
	\begin{itemize}
		\item Given two categorical variables, we often want to determine if they are independent versus dependent  \pause
		\item[]
		\item We will develop a $\chi^2$ test that determines whether the ``amount'' of dependence that we measure between two categorical random variables is greater than what we would expect due to chance alone 
	\end{itemize}
\end{frame}

\begin{frame}{Dependence \& Proportion tables}
\begin{itemize}
	\item Recall: $r$ is the number of rows and $c$ is the number of columns  \pause
	\item[]
	\item Population proportions:  \pause
	\begin{itemize}
		\item The population proportion in row $i$ and column $j$ is denoted $\pi_{ij}$  \pause
		\item The total proportion for row $i$ is $\pi_{i.}$  \pause
		\item The total proportion for column $j$ is $\pi_{.j}$  \pause
		\item If the row and column probabilities are independent then: $\pi_{ij}=\pi_{i.}\pi_{.j}$  \pause
		\item[]
	\end{itemize}
	\item A fictitious example of two independent variables:  \pause
	\begin{center}
		\begin{tabular}{|l|ccc|c|}
			\hline
			& \multicolumn{3}{c|}{Duration of College degree} & \\
			Major & $<4$ years & 4 years & $>4$ years & Total \\ \hline
			Physical science & 80 & 140 & 180 & 400 \\ 
			Life science & 120 & 210 & 270 & 600 \\
			Liberal arts & 140 & 245 & 315 & 700\\ 
			Other & 60 & 105 & 135 & 300 \\ \hline
			Total & 400 & 700 & 900 & 2000\\ \hline
		\end{tabular}
	\end{center}
\end{itemize}
\end{frame}

\begin{frame}{Dependence \& Proportion tables}
\begin{itemize}
	\item Recall: $r$ is the number of rows and $c$ is the number of columns
		\item[]
	\item Population proportions:
	\begin{itemize}
		\item The population proportion in row $i$ and column $j$ is denoted $\pi_{ij}$
		\item The total proportion for row $i$ is $\pi_{i.}$
		\item The total proportion for column $j$ is $\pi_{.j}$
		\item If the row and column probabilities are independent then: $\pi_{ij}=\pi_{i.}\pi_{.j}$
		\item[]
	\end{itemize}
	\item A fictitious example of two independent variables:
	\begin{center}
		\begin{tabular}{|l|ccc|c|}
			\hline
			& \multicolumn{3}{c|}{Duration of College degree} & \\
			Major & $<4$ years & 4 years & $>4$ years & Total \\ \hline
			Physical science & 0.04 & 0.07 & 0.09 & 0.20 \\ 
			Life science & 0.06 & 0.105 & 0.135 & 0.30 \\
			Liberal arts & 0.07 & 0.1225 & 0.1575 & 0.35\\ 
			Other & 0.03 & 0.0525 & 0.0675 & 0.15 \\ \hline
			Total & 0.20 & 0.35 & 0.45 & \\ \hline
		\end{tabular}
	\end{center}
\end{itemize}
\end{frame}

\begin{frame}{Dependence \& Proportion tables}
\begin{itemize}
	\item Recall: $r$ is the number of rows and $c$ is the number of columns
	\item[]
	\item Population proportions:
	\begin{itemize}
		\item The population proportion in row $i$ and column $j$ is denoted $\pi_{ij}$
		\item The total proportion for row $i$ is $\pi_{i.}$
		\item The total proportion for column $j$ is $\pi_{.j}$
		\item If the row and column probabilities are independent then: $\pi_{ij}=\pi_{i.}\pi_{.j}$
		\item[]
	\end{itemize}
	\item \textbf{Estimated expected value:} Under the hypothesis of independence, the estimated expected value is:  \pause
	\begin{gather*}
		\hat{E}_{ij} =n\frac{(n_{i.})}{n} \frac{(n_{.j})}{n} =  \frac{(n_{i.})(n_{.j})}{n} = n \hat{\pi}_{ij}
	\end{gather*}
\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of independence}{Process}
	\begin{itemize}
		\item Hypotheses:  \pause
		\begin{itemize}
			\item $H_0:$ The row and column variables are independent  \pause
			\item $H_a:$ The row and column variables are dependent (associated)  \pause
			\item[]
		\end{itemize}
	\item Test statistic:
	\begin{gather*}
		X^2 = \sum_{i,j} \frac{(n_{ij}-\hat{E}_{ij})^2}{\hat{E}_{ij}}
	\end{gather*}  \pause
	\item[]
	\item Rejection rule: Reject $H_0$ if $X^2 > \chi^2_{\alpha,\text{df}=(r-1)(c-1)}$ with level of significance, p-value: $P(\chi^2 > X^2)$
	\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of independence}{Example}
	\begin{itemize}
		\item Back to the length of stay and visitation data for schizophrenic patients in mental hospitals in London  \pause
		\begin{itemize}
			\item Let's determine if there is evidence that length of stay and the pattern of visitation are dependent ($H_a$), at $\alpha = .05$  \pause
			\item[]
			\item RR: Reject $H_0$ if $X^2 > \chi^2_{\alpha,\text{df}=(r-1)(c-1)}=\chi^2_{0.05,4}= 9.488$  \pause
			\item[]
		\end{itemize}
		\item Proportion table:  \pause
		\begin{center}
			\begin{tabular}{|l|ccc|c|}
				\hline
				& \multicolumn{3}{c|}{Length of Stay (LOS)} & \\
				Visitation & 2-9 & 10-19 & 20+ & All LOS \\ \hline
				Regular & 0.326 & 0.121 & 0.023 & 0.470\\ 
				$<1/\text{month}$ & 0.045 & 0.083 & 0.076 & 0.205 \\
				Never & 0.068 & 0.136 & 0.121 & 0.326\\ \hline
				Total & 0.439 & 0.341 & 0.220 & 1.00\\ \hline
			\end{tabular}
		\end{center}
	\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of independence}{Example}
	\begin{itemize}
		\item Proportion table:
		\vspace{1mm}
		{\scriptsize
		\begin{center}
			\begin{tabular}{|l|ccc|c|}
				\hline
				& \multicolumn{3}{c|}{Length of Stay (LOS)} & \\
				Visitation & 2-9 & 10-19 & 20+ & All LOS \\ \hline
				Regular & 0.326 & 0.121 & 0.023 & 0.470\\ 
				$<1/\text{month}$ & 0.045 & 0.083 & 0.076 & 0.205 \\
				Never & 0.068 & 0.136 & 0.121 & 0.326\\ \hline
				Total & 0.439 & 0.341 & 0.220 & 1.00\\ \hline
			\end{tabular}
		\end{center}}  \pause
	\vspace{1mm}
	\item Expected value of the proportions under the null hypothesis:
	\vspace{1mm}
		{\scriptsize
			\begin{center}
				\begin{tabular}{|l|ccc|c|}
					\hline
					& \multicolumn{3}{c|}{Length of Stay (LOS)} & \\
					Visitation & 2-9 & 10-19 & 20+ & All LOS \\ \hline
					Regular           &0.2064 &0.1601 &0.1032 & 0.470\\
					$<1/\text{month}$ &0.0899 &0.0697 &0.0449 & 0.205\\
					Never             &0.1432 &0.1111 &0.0716 & 0.326\\ \hline
					Total & 0.439 & 0.341 & 0.220 & 1.00\\ \hline
				\end{tabular}
		\end{center}}
	\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of independence}{Example}
\begin{itemize}
	\item Expected value of the proportions under the null hypothesis:
	\vspace{1mm}
	{\scriptsize
		\begin{center}
		\begin{tabular}{|l|ccc|c|}
			\hline
			& \multicolumn{3}{c|}{Length of Stay (LOS)} & \\
			Visitation & 2-9 & 10-19 & 20+ & All LOS \\ \hline
			Regular           &0.2064 &0.1601 &0.1032 & 0.470\\
			$<1/\text{month}$ &0.0899 &0.0697 &0.0449 & 0.205\\
			Never             &0.1432 &0.1111 &0.0716 & 0.326\\ \hline
			Total & 0.439 & 0.341 & 0.220 &1.00 \\ \hline
		\end{tabular}
	\end{center}}  \pause
	\vspace{1mm}
	\item Estimated expected values, $\hat{E}_{ij}$:
	\vspace{1mm}
	{\scriptsize
		\begin{center}
			\begin{tabular}{|l|ccc|c|}
				\hline
				& \multicolumn{3}{c|}{Length of Stay (LOS)} & \\
				Visitation & 2-9 & 10-19 & 20+ & All LOS \\ \hline
				Regular           &27.2448 &21.1332& 13.6224& 62.0004  \\
				$<1/\text{month}$ &11.8668 & 9.2004& 5.9268& 26.9940 \\
				Never             &18.9024 &14.6652&  9.4512& 43.0188\\ \hline
				Total & 58.0140 & 44.9988 & 29.004 & 132.0132\\ \hline
			\end{tabular}
	\end{center}}
\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of independence}{Example}
\begin{itemize}
	\item Table of values, $\frac{(n_{ij}-\hat{E}_{ij})^2}{\hat{E}_{ij}}$:
	\vspace{1mm}
	{\scriptsize
		\begin{center}
			\begin{tabular}{|l|ccc|c|}
				\hline
				& \multicolumn{3}{c|}{Length of Stay (LOS)} & \\
				Visitation & 2-9 & 10-19 & 20+ & All LOS \\ \hline
				Regular           &9.1110 &1.2468 &8.2831 & 18.6409\\
				$<1/\text{month}$ &2.9005 &0.3520 &2.7993 & 6.0518\\
				Never             &5.1876 &0.7583 &4.5377 & 10.4836\\ \hline
				Total & 17.1991 & 2.3571 &15.6201& 35.1763 \\ \hline
			\end{tabular}
	\end{center}}  \pause
	\vspace{2mm}
	\item Conclusion: Since $35.1763 > 9.488$, we reject $H_0$. We have evidence that there is dependency between visitation patterns and the length of stay for these patients. The p-value is $P(\chi^2 > 35.1763) =0.0000004$
\end{itemize}
\end{frame}

\begin{frame}{Important note on the $\chi^2$ test of independence}
	\begin{itemize}
		\item As with any hypothesis test, the level of significance (and equivalently whether the null hypothesis is rejected), is a function of both the strength of an association / effect size and the sample size  \pause
		\item[]
		\item For a fixed strength of an association, the larger the sample size, the smaller the p-value  \pause
		\item[]
		\item Consequently, p-values should not be used to determine the strength of an association; only the likelihood the observed result was due to random chance
	\end{itemize}
\end{frame}

\section{$\chi^2$ test of homogeneity}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{$\chi^2$ test of homogeneity}
	\begin{itemize}
		\item The $\chi^2$ test of independence described earlier is for when you have a sample from one population and would like to determine if two categorical variables are dependent / independent  \pause
		\item[]
		\item Now we consider the situation that you have a sample from two or more populations / sub-populations and you wish to compare the distribution of observations across a categorical variable  \pause
		\item[]
		\item This is a slightly different type of problem \emph{with the same statistical hypothesis testing framework}
	\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of homogeneity}
	\begin{itemize}
		\item Example research question: There are 3 genotypes for ApoCI, \{AA, AB, BB\}. Is the distribution of Apolipoprotein C-I (ApoCI) genotype the same for Alzheimer's patients as in patients without Alzheimer's disease?   \pause
		\item[]
		\item This was studied in a Chinese population by Shi, J., et al. (2003). doi: 10.1034/j.1600-0404.2003.00193.x  \pause
		\item[]
		\item The researchers recruited a cohort of 257 patients with Alzheimer's disease and 242 age-matched controls
	\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of homogeneity}{Hypotheses}
\begin{itemize}
	\item Hypotheses:  \pause
	\begin{itemize}
		\item $H_0: (\pi_{11}, \pi_{21}, \hdots, \pi_{r1})=(\pi_{12}, \pi_{22}, \hdots, \pi_{r2})=\dots = (\pi_{13}, \pi_{23}, \hdots, \pi_{r3})$
		\item $H_a: \pi_{ij}$ are not equal across populations / sub-populations
		\item[]
	\end{itemize}  \pause
	\item Example research question: There are 3 genotypes for ApoCI, \{AA, AB, BB\}. Is the distribution of Apolipoprotein C-I (ApoCI) genotype the same for Alzheimer's patients as in patients without the disease?  \pause 
	\item[]
	\item This was studied in a Chinese population by Shi, J., et al. (2003). doi: 10.1034/j.1600-0404.2003.00193.x  \pause
	\item[]
	\item The researchers recruited a cohort of 257 patients with Alzheimer's disease and 242 age-matched controls
\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of homogeneity}{Example}
\begin{itemize}
	\item Example research question: There are 3 genotypes for ApoCI, \{AA, AB, BB\}. Is the distribution of Apolipoprotein C-I (ApoCI) genotype the same for Alzheimer's patients as in patients without the disease?  
	\item[]
	\item Hypotheses:
	\begin{itemize}
		\item $H_0: (\pi_{11}, \pi_{21}, \hdots, \pi_{r1})=(\pi_{12}, \pi_{22}, \hdots, \pi_{r2})=\dots = (\pi_{13}, \pi_{23}, \hdots, \pi_{r3})$
		\item $H_a: \pi_{ij}$ are not equal across populations / sub-populations
		\item[]
	\end{itemize}
	\item The data from that study:  \pause
	\begin{center}
		\begin{tabular}{c|cc}
			\hline
			\textbf{ApoCI genotype} & \textbf{Alzheimer's (AD)} & \textbf{No AD} \\ \hline
			AA & 14 & 5 \\
			AB & 99 & 87 \\
			BB & 144 & 150 \\ \hline
		\end{tabular}
	\end{center}
\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of homogeneity}{Example}
\begin{itemize}
	\item The data from that study:
	\begin{center}
		\begin{tabular}{c|cc|c}
			\hline
			\textbf{ApoCI genotype} & \textbf{Alzheimer's (AD)} & \textbf{No AD} & \textbf{Total} \\ \hline
			AA & 14 & 5 &  19\\
			AB & 99 & 87 &  186\\
			BB & 144 & 150 &  294\\ \hline
			\textbf{Total} & 257 & 242 & 499
		\end{tabular}
	\end{center}  \pause
	\item[]
	\item Using the formula $\hat{E}_{ij} = \frac{(n_{i.})(n_{.j})}{n}$:  \pause
	\begin{center}
	\begin{tabular}{c|cc|c}
		\hline
		\textbf{ApoCI genotype} & \textbf{Alzheimer's (AD)} & \textbf{No AD} & \textbf{Total}\\ \hline
		AA &   9.7856 &   9.2144 & 19\\
		AB &  95.7956&   90.2044 & 186\\
		BB & 151.4188 & 142.5812 & 294\\ \hline
		\textbf{Total} & 257 & 242 & 499
	\end{tabular}
\end{center}
\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of homogeneity}{Example}
	\begin{itemize}
		\item Using the formula $\hat{E}_{ij} = \frac{(n_{i.})(n_{.j})}{n}$:
		\begin{center}
			\begin{tabular}{c|cc|c}
				\hline
				\textbf{ApoCI genotype} & \textbf{Alzheimer's (AD)} & \textbf{No AD} & \textbf{Total}\\ \hline
				AA &   9.7856 &   9.2144 & 19\\
				AB &  95.7956&   90.2044 & 186\\
				BB & 151.4188 & 142.5812 & 294\\ \hline
				\textbf{Total} & 257 & 242 & 499
			\end{tabular}
		\end{center}\pause
	\item Table of values, $\frac{(n_{ij}-\hat{E}_{ij})^2}{\hat{E}_{ij}}$: \pause
			\begin{center}
		\begin{tabular}{c|cc}
			\hline
			\textbf{ApoCI genotype} & \textbf{Alzheimer's (AD)} & \textbf{No AD}\\ \hline
			AA& 1.8150310& 1.9275446\\
			AB& 0.1071884& 0.1138324\\
			BB& 0.3634859& 0.3860158\\ \hline
		\end{tabular}
	\end{center}
	\end{itemize}
\end{frame}

\begin{frame}{$\chi^2$ test of homogeneity}{Example}
\begin{itemize}
	\item Table of values, $\frac{(n_{ij}-\hat{E}_{ij})^2}{\hat{E}_{ij}}$: 
	\begin{center}
		\begin{tabular}{c|cc}
			\hline
			\textbf{ApoCI genotype} & \textbf{Alzheimer's (AD)} & \textbf{No AD}\\ \hline
			AA& 1.8150310& 1.9275446\\
			AB& 0.1071884& 0.1138324\\
			BB& 0.3634859& 0.3860158\\ \hline
		\end{tabular}
	\end{center} \pause
		\item Test statistic: \pause
		\begin{gather*}
		X^2 = \sum_{i,j} \frac{(n_{ij}-\hat{E}_{ij})^2}{\hat{E}_{ij}} = 4.7131
		\end{gather*} \pause
		\item Since the degrees of freedom is 2, the p-value is $P(\chi^2 > 4.7131)=0.0947$ \pause
		\item[]
		\item So there is some evidence that this result would be unlikely due to chance alone; genotype appears to be associated with AD
\end{itemize}
\end{frame}

\section{The strength of an association}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{The strength of an association}
	\begin{itemize}
		\item Both the $\chi^2$ test of independence and homogeneity tell us how rare it is to see a contingency table such as the one we have observed if the null hypothesis were true \pause
		\item[]
		\item However, the level of significance from those tests does not tell us the strength of the association \pause
		\item[]
		\item For this we can look directly at the proportions / percentages to make inferences \pause
	\end{itemize}
\end{frame}

\begin{frame}{Proportions from a contingency table}
	\begin{itemize}
		\item Proportions of total: \pause
		{\scriptsize
		\begin{center}
			\begin{tabular}{|l|ccc|}
				  \hline
				  & \multicolumn{3}{c|}{Length of Stay (LOS)}\\
  				Visitation & 2-9 & 10-19 & 20+ \\ \hline
				Regular          & 0.326& 0.121& 0.023 \\
				Less than monthly& 0.045& 0.083& 0.076 \\
				Never            & 0.068& 0.136& 0.121 \\ \hline
			\end{tabular}
		\end{center}} \pause
	 \vspace{1mm}
		\item Proportions within rows:
			{\scriptsize
			\begin{center}
				\begin{tabular}{|l|ccc|}
					\hline
					& \multicolumn{3}{c|}{Length of Stay (LOS)}\\
					Visitation & 2-9 & 10-19 & 20+ \\ \hline
				Regular           & 0.694 & 0.258 & 0.048 \\
				Less than monthly & 0.222 & 0.407 & 0.370 \\
				Never             & 0.209 & 0.419 & 0.372 \\ \hline
				\end{tabular}
		\end{center}} \pause
	\vspace{1mm}
		\item Proportions within columns:
		{\scriptsize
			\begin{center}
				\begin{tabular}{|l|ccc|}
					\hline
					& \multicolumn{3}{c|}{Length of Stay (LOS)}\\
					Visitation & 2-9 & 10-19 & 20+ \\ \hline
				Regular            &0.741  &0.356  &0.103 \\
				Less than monthly  &0.103  &0.244  &0.345 \\
				Never              &0.155  &0.400  &0.552 \\ \hline
				\end{tabular}
		\end{center}}
	\end{itemize}
\end{frame}

\begin{frame}{Proportions from a contingency table}
\begin{itemize}
	\item Proportions within rows:
	\begin{itemize}
		\item Of those who receive regular visits, 69.4\% will have a length of stay of 2-9 years, while 4.8\% will have a length of stay of 20+ years
	\end{itemize}
	{\scriptsize
		\begin{center}
			\begin{tabular}{|l|ccc|}
				\hline
				& \multicolumn{3}{c|}{Length of Stay (LOS)}\\
				Visitation & 2-9 & 10-19 & 20+ \\ \hline
				Regular           & 0.694 & 0.258 & 0.048 \\
				Less than monthly & 0.222 & 0.407 & 0.370 \\
				Never             & 0.209 & 0.419 & 0.372 \\ \hline
			\end{tabular}
	\end{center}} \pause
	\vspace{1mm}
	\item Proportions within columns:
	\begin{itemize}
		\item Of those with a length of stay of 20+ years, 10.3\% will have regular visits compared to 74.1\% for those with a length of stay of 2-9 years 
	\end{itemize}
	{\scriptsize
		\begin{center}
			\begin{tabular}{|l|ccc|}
				\hline
				& \multicolumn{3}{c|}{Length of Stay (LOS)}\\
				Visitation & 2-9 & 10-19 & 20+ \\ \hline
				Regular            &0.741  &0.356  &0.103 \\
				Less than monthly  &0.103  &0.244  &0.345 \\
				Never              &0.155  &0.400  &0.552 \\ \hline
			\end{tabular}
	\end{center}}
\end{itemize}
\end{frame}

\begin{frame}{The end of Lecture \#17}
	\begin{center}
		\includegraphics[width=.8\linewidth]{DSC_0177_v1}
	\end{center}
\end{frame}

\end{document}