\documentclass[xcolor=dvipsnames]{beamer} 
\usetheme{AnnArbor}
\usecolortheme{beaver}

\usepackage{amsmath,graphicx,booktabs,tikz,subfig,color,lmodern}
\definecolor{mycol}{rgb}{.4,.85,1}
\setbeamercolor{title}{bg=mycol,fg=black} 
\setbeamercolor{palette primary}{use=structure,fg=white,bg=red}
\setbeamercolor{block title}{fg=white,bg=red!50!black}
% \setbeamercolor{block title}{fg=white,bg=blue!75!black}

\title[Lecture 5]{Lecture 5: Events and Probability Laws}
\author[Patrick Trainor]{Patrick Trainor, PhD, MS, MA}
\institute[NMSU]{New Mexico State University}
\date{September 4, 2019}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}{Outline}
\tableofcontents[hideallsubsections]
\end{frame}

\section{Introduction}
\begin{frame}{Outline}
	\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Uncertainty}
	\begin{itemize}
		\item We continuously elude to the fact that we can use samples to make inferences about a population
		\item[]
		\item A sample does not perfectly match the population--there is ``uncertainty'' when we use a statistic estimated from a sample (e.g. the sample mean) to make an inference about a population parameter (e.g. the population mean)
		\item[]
		\item Probability theory helps us understand the uncertainty of estimates made from samples
	\end{itemize}
\end{frame}

\begin{frame}{Uncertainty}
\begin{itemize}
	\item More importantly, we have to make decisions with imperfect information every day
	\item[]
	\item A mathematical understanding of uncertainty (probability theory) can help us make decisions in these cases
	\item[]
	\item Sometimes our understanding of uncertainty can have huge consequences. Imagine a positive finding on a genetic test that tells a set of would be parents that if they have a baby, the child could be born with a rare [and terrible] disease)
	\begin{itemize}
		\item What if the test has a false positive rate of 80\%?
		\item What if the test has a false positive rate of 0.01\%?
	\end{itemize}
\end{itemize}
\end{frame}

\section{Outcomes, events, and probability statements}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Outcomes \& events}
	\begin{itemize}
		\item \textbf{\emph{An outcome:}} Given a non-deterministic process, a distinct result is called an outcome
		\begin{itemize}
			\item Drawing a card from a deck is a non-deterministic process; drawing a 4 of spades is a result (hence it is an outcome)
		\end{itemize}
		\item[]
		\item \textbf{\emph{An event:}} An event is a collection of outcomes
		\begin{itemize}
			\item Drawing an even spade is an event, the collection of outcomes is {2 of spades, 4 of spades, 6 of spades, 8 of spades, 10 of spades}
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Probabilities}
	\begin{itemize}
		\item \textbf{\emph{Probability of an event:}} The probability of an event is the number of outcomes that comprise an event divided by the total number of possible events
		\item[]
		\item Mathematical definition: $P(E) = \frac{N_E}{N}$, where $N_E$ is the number of outcomes that comprise an event and $N$ is the total number of possible outcomes
	\end{itemize}
\end{frame}

\begin{frame}{Probabilities}
\begin{itemize}
	\item Empirical probabilities: ``If an experiment is
	repeated a large number of times and event E occurs 30\% of the time, then .30
	should be a very good approximation to the probability of event E''
	\item[] 
	\item Mathematical definition of empirical probabilities: $P(E) \approx \frac{n_E}{n}$ where $n_e$ denotes the number of observed events out of $n$ observations
\end{itemize}
\end{frame}

\begin{frame}{Probabilities}{What's the difference?}
	\begin{itemize}
		\item Book calls $P(E) = \frac{N_E}{N}$ ``classical probability'' and $P(E) \approx \frac{n_E}{n}$ ``relative frequency probability''
		\item[]
		\item When we talk about $P(E) = \frac{N_E}{N}$ we are referring to probabilities we can compute without observing anything
		\begin{itemize}
			\item  We know the probability of getting an Ace of Spades is $1/52$ (we don't have to draw cards over and over to figure this out)--it is theoretical
		\end{itemize}
	\item[]
	\item However, if we want to know the probability of death following being struck by lightning we would take a sample of $n$ lightning strike cases and determine how many of them resulted in death $n_e$ to compute $P(E) \approx \frac{n_E}{n}$
	\begin{itemize}
		\item This is not theoretical. We have to go count. It is ``empirical''
	\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Probabilities}{Empirical probabilities converge to theoretical}
	\begin{center}
		\includegraphics[width=0.85\linewidth]{bar1}
	\end{center}
\end{frame}

\begin{frame}{Probabilities}{Empirical probabilities converge to theoretical}
\begin{center}
	\includegraphics[width=0.85\linewidth]{bar2}
\end{center}
\end{frame}

\begin{frame}{Probabilities}{Empirical probabilities converge to theoretical}
\begin{center}
	\includegraphics[width=0.85\linewidth]{bar3}
\end{center}
\end{frame}

\begin{frame}{Probabilities}{Empirical probabilities converge to theoretical}
\begin{center}
	\includegraphics[width=0.85\linewidth]{bar4}
\end{center}
\end{frame}

\begin{frame}{Probabilities}{Empirical probabilities converge to theoretical}
\begin{center}
	\includegraphics[width=0.85\linewidth]{bar5}
\end{center}
\end{frame}

\begin{frame}{Probabilities}{Empirical probabilities converge to theoretical}
\begin{center}
	\includegraphics[width=0.85\linewidth]{bar6}
\end{center}
\end{frame}

\section{Probability laws}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{A first law}
	\begin{itemize}
		\item Probabilities are positive and less than or equal to one
		\item[]
		\item Let $A$ be an event. Then $0 \leq P(A) \leq 1$
		\item[]
		\item The probability of any event is somewhere between impossible and guaranteed
	\end{itemize}
\end{frame}

\begin{frame}{Mutually exclusive}
	\begin{itemize}
		\item \textbf{\emph{Mutually exclusive:}} Two events $A$ and $B$ are mutually exclusive if the occurrence of one event precludes the possibility of the occurrence of the other event
		\item[]
		\item Let's roll two dice. Define $A$ to be the event that the sum is 7 and define $B$ to be the event that the sum is 11
		\begin{center}
			\includegraphics[scale=.1]{dice-25637_640}
		\end{center}
		\begin{gather*}
			P(A \text{ and } B) = 0
		\end{gather*}
	\end{itemize}
\end{frame}

\begin{frame}{Mutually exclusive}
	\begin{itemize}
		\item Define $A$ to be the event that the sum is 7 and define $B$ to be the event that the sum is 11. What is the probability of either $A$ or $B$ happening?
		\begin{center}
			\includegraphics[scale=.8]{allDice2}
		\end{center}
		\item Here are the outcomes that comprise $A$: $\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\}$
		\item Here are the outcomes that comprise $B$: $\{(5,6), (6,5)\}$
		\item So $P(A \text{ or } B) = \frac{N_{A\text{ or B}}}{N} = \frac{8}{36} = \frac{2}{9}$
	\end{itemize}
\end{frame}

\begin{frame}{Mutually exclusive}
\begin{itemize}
	\item Another law: If two events are mutually exclusive, then $P(A \text{ or } B) = P(A) + P(B)$
	\item[]
	\item Define $A$ to be the event that the sum is 7 and define $B$ to be the event that the sum is 11. What is the probability of either $A$ or $B$ happening?
	\begin{gather*}
		P(A \text{ or } B) = \frac{6}{36} + \frac{2}{36} = \frac{8}{36} = \frac{2}{9}
	\end{gather*}
\end{itemize}
\end{frame}

\begin{frame}{The complement}
	\begin{itemize}
		\item \textbf{\emph{The complement:}} The complement of an event, $A$, is the event that $A$ does not occur. We denote it $A^c$
		\begin{itemize}
			\item The book denotes it as $\bar{A}$
		\end{itemize}
	\item[]
	\item Another law! $P(A) + P(A^c) = 1$
	\begin{itemize}
		\item What is the probability of flipping a coin and getting heads or tails?
	\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Union and Intersection}
	\begin{itemize}
		\item \textbf{\emph{Union:}} The union of two events, $A$ and $B$, is the set of all outcomes that are included in either $A$ or $B$ (or both). Denoted $A \cup B$
		\item[]
		\item \textbf{\emph{Intersection:}} The intersection of two events, $A$ and $B$, is the set of all outcomes that are included in both $A$ and $B$. Denoted $A \cap B$
		\item[]
		\item The probability of the union of A and B, that is $P(A\cup B)$ is $P(A \cup B) = P(A) + P(B) - P(A\cap B)$
	\end{itemize}
\end{frame}

\begin{frame}{Break for data}
\begin{itemize}
	\item Back to the Titanic passenger data:
	\begin{center}
		\begin{tabular}{|c|c|c|} \hline
			\textbf{Class} & \textbf{Survived} & \textbf{Frequency} \\ \hline \hline
			1st  & No       &        122 \\ \hline 
			1st   &Yes       &       203\\ \hline 
			2nd   &No         &      167\\ \hline 
			2nd   &Yes         &     118\\ \hline 
			3rd   &No           &    528\\ \hline 
			3rd   &Yes           &   178\\ \hline 
			Crew  &No             &  673\\ \hline 
			Crew  &Yes             & 212\\ \hline 
		\end{tabular}
	\end{center}
	\item[]
	\item Let $A$ be the event that a passenger was in first class and let $B$ be the event that the passenger survived. First, let's make a Venn diagram and then compute the union and intersection of the events.
\end{itemize}
\end{frame}

\begin{frame}{Titanic data}{Venn Diagram}
	\begin{center}
		\includegraphics{TitanicVenn}
	\end{center}
\end{frame}

\begin{frame}{Titanic data}{Intersection}
\begin{center}
	\includegraphics[scale=.75]{TitanicVenn}
\end{center}
\begin{align*}
P(A \cap B) &= \frac{203}{2201} = 0.092
\end{align*}
\end{frame}

\begin{frame}{Titanic data}{Union}
\begin{center}
	\includegraphics[scale=.75]{TitanicVenn}
\end{center}
\begin{align*}
	P(A \cup B) &= P(A) + P(B) - P(A\cap B)\\
	&= \frac{(122 + 203)}{2201} + \frac{(203 + 508)}{2201} - \frac{203}{2201} \\
	&= \frac{833}{2201} = 0.378
\end{align*}
\end{frame}

\begin{frame}{Titanic data}{A few more problems}
	\begin{enumerate}
		\item What do the events $A^c$ and $B^c$ represent? What are their probabilities?
		\item[]
		\item What is the probability $P(A^c \cap B)$? What does this event represent?
		\item[] 
		\item What is the probability $P(A^c \cap B)$? What does this event represent?
	\end{enumerate}
\end{frame}

\begin{frame}{Titanic data}{A few more problems}
\begin{enumerate}
	\item What do the events $A^c$ and $B^c$ represent? What are their probabilities?\\
	$A^c$ is the event that a passenger is not in first class. $B^c$ is the event a passenger did not survive. 
	\begin{align*}
		P(A^c) &= \frac{1876}{2201} = 0.852 \\
		P(B^c) &= \frac{1490}{2201} = 0.677
	\end{align*}
	\item What is the probability $P(A^c \cap B)$? What does this event represent?
	\item[] 
	\item What is the probability $P(A^c \cap B)$? What does this event represent?
\end{enumerate}
\end{frame}

\begin{frame}{Titanic data}{A few more problems}
\begin{enumerate}
	\item What do the events $A^c$ and $B^c$ represent? What are their probabilities?
	\item What is the probability $P(A^c \cap B)$? What does this event represent? \\
	This is the event that a passenger is not in first class and does survive.
	\begin{gather*}
		P(A^c \cap B) = \frac{508}{2201} = 0.231
	\end{gather*}
	\item What is the probability $P(A^c \cup B)$? What does this event represent?
\end{enumerate}
\end{frame}

\begin{frame}{Titanic data}{A few more problems}
\begin{enumerate}
	\item What do the events $A^c$ and $B^c$ represent? What are their probabilities?
	\item What is the probability $P(A^c \cap B)$? What does this event represent? 
	\item What is the probability $P(A^c \cup B)$? What does this event represent? \\
	This is the event that a passenger is either not in first class or does survive.
	\begin{align*}
		P(A^c \cup B) &= P(A^c) + P(B) - P(A^c \cap B)\\ 
		&= 0.852 + \frac{711}{2201} - 0.231 \\
		&= 0.852 + 0.323 - 0.231 \\
		&= 0.944
	\end{align*}
\end{enumerate}
\end{frame}

\section{Conditional probability}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Conditional Probability}
	\begin{itemize}
		\item \textbf{\emph{Conditional probability:}} Let $A$ and $B$ be events with nonzero probabilities. The conditional probability of event $A$ given that $B$ has occured is:
		\begin{gather*}
		P(A|B) = \frac{P(A \cap B)}{P(B)}
		\end{gather*}
		\item Let $A$ be the event that a passenger was in first class and let $B$ be the event that the passenger survived. The conditional probability a passenger is a first class passenger given that they survived is:
		\begin{align*}
		P(A|B) &= \frac{P(A \cap B)}{P(B)} \\
		&=\frac{203 / 2201}{711 / 2201}\\ 
		&= 0.286
		\end{align*}
	\end{itemize}
\end{frame}

\begin{frame}{Conditional Probability}
\begin{itemize}
	\item The conditional probability of interest can be switched: 
	\begin{align*}
	P(B|A) &= \frac{P(B \cap A)}{P(A)}
	\end{align*}
	\item Let's calculate this conditional probability. What event is represented by $B|A$?
\end{itemize}
\end{frame}

\begin{frame}{Conditional Probability}
\begin{itemize}
	\item Let's calculate this conditional probability. What event is represented by $B|A$? \\
	
	The event $B|A$ is the probability a passenger survived given that they were a first class passenger.
	\begin{align*}
	P(B|A) &= \frac{P(B \cap A)}{P(A)} \\
	&= \frac{203 / 2201}{325 / 2201} \\
	&=  0.625
	\end{align*}
\end{itemize}
\end{frame}

\begin{frame}{Conditional Probability}
	\begin{itemize}
		\item \textbf{\emph{The multiplication law:}} The probability of the intersection of two events, $A$ and $B$, is:
		\begin{align*}
		P(A \cap B) &= P(A) P(B|A) \\
		&= P(B)P(A|B)
		\end{align*}
		\item If we know $P(A)$ and $P(B|A)$ we can calculate $P(A \cap B$)
		\item[]
		\item We know the probability a passenger is a first class passenger, $P(A)$, and we know the probability a passenger survived given they were a first class passenger $P(B|A)$, so we can calculate the probability a passenger was a first class passenger and survived $P(A \cap B$).
	\end{itemize}
\end{frame}

\begin{frame}{Conditional probability}
Example problem: The probability a passenger was not in first class is 0.852 and the probability a passenger survived given that they were not in first class is 0.271. What is the probability that a randomly chosen passenger was not in first class and did survive?
\end{frame}

\begin{frame}{Conditional probability}
	Example problem: The probability a passenger was not in first class is 0.852 and the probability a passenger survived given that they were not in first class is 0.271. What is the probability that a randomly chosen passenger was not in first class and did survive?
	\begin{align*}
		P(A^c \cap B) &= P(A^c) P(B|A^c) \\
		&= 0.852 \times 0.271 \\
		&= 0.231
	\end{align*}
\end{frame}

\section{Independence}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Independence}
	\begin{itemize}
		\item \textbf{\emph{Independent events:}} Suppose that the probability of an event, $A$, is the same regardless of whether event $B$ has occured. Then $A$ and $B$ are independent events.
		\item[]
		\item Mathematically, if $P(A|B) = P(A)$ or equivalently, $P(A|B) = P(A|B^c) = P(A)$, or $P(B|A) = P(B)$, then $A$ and $B$ are independent.  
		\item[]
		\item \textbf{\emph{Dependent events:}} If two events $A$ and $B$ are not independent, then they are dependent, that is $P(A|B) \neq P(A)$ and it will also be true that $P(B|A) \neq P(B)$
	\end{itemize}
\end{frame}

\begin{frame}{Independence}{Example}
A school admits the following number of students by gender:
\begin{center}
		\begin{tabular}{c|cc}
		& \textbf{Gender} & \\
		\textbf{Admitted} & Male & Female \\ \hline
		Yes & 202 & 210 \\
		No & 303 & 315
	\end{tabular}
\end{center}
Are the gender of the student and whether the student was admitted independent?
\end{frame}

\begin{frame}{Independence}{Example}
\begin{center}
	\begin{tabular}{c|cc}
		& \textbf{Gender} & \\
		\textbf{Admitted} & Male & Female \\ \hline
		Yes & 202 & 210 \\
		No & 303 & 315
	\end{tabular}
\end{center}
Are the gender of the student and whether the student was admitted independent? \\ 
Let $A$ be the event that a student is admitted, and let $B$ be the event that a student is male. Let's check if $P(A|B) = P(A)$ or $P(A|B) \neq P(A)$.
\begin{gather*}
	P(A|B) = P(A \cap B) P(B) = \frac{202/1030}{505/1030}= \frac{202}{505} = 0.4 \\
	P(A) = \frac{412}{1030} = 0.4
\end{gather*}
Since $P(A|B) = P(A)$ we conclude that the student's gender and admission are independent. 
\end{frame}

\begin{frame}{Another example}
	Example problem: Is the probability that a passenger survived the sinking of the Titanic independent of whether or not they were a first class passenger? \\
	Let's check if $P(A|B) = P(A)$ or $P(A|B) \neq P(A)$, where $A$ is the event that the passenger is a first class passenger, and $B$ is the event that the passenger survived.
	\begin{gather*}
		P(A|B) = 0.286 \\
		P(A) = \frac{325}{2201} = 0.148
	\end{gather*}
	So we can conclude that whether a passenger survived or not is dependent on whether or not they were first class as $P(A|B) \neq P(A)$.
\end{frame}

\section{Bayes' formula}
\begin{frame}{Outline}
\tableofcontents[currentsection,subsectionstyle=show/shaded/hide]
\end{frame}

\begin{frame}{Motivation}
Imagine you are the manager of a small airline that flys super important people around. You need to test your pilots for drugs. I manufacture a drug test and tell you that if a person has done drugs, there is a 97.5\% chance we will catch them (positive test). You test your pilots, and 3 of them fail. One of the drug test failures, Sally, claims she is innocent. Should you believe her? 

\vspace{10pt}
Answer: \emph{It depends.}

\end{frame}

\begin{frame}{Motivation}
	There are many ways that we can have a 97.5\% chance of catching those who have done drugs. Here are two different ways:
	\vspace{10 pt}
	\begin{columns}
		\begin{column}{0.5 \textwidth}
			\begin{tabular}{c|cc}
				& \textbf{Drug use} & \\
				\textbf{Test A} & + & - \\ \hline
				+ & 2925 & 450 \\
				- & 75 & 6550\\
			\end{tabular}
		\end{column}
		\begin{column}{0.5 \textwidth}
			\begin{tabular}{c|cc}
				& \textbf{Drug use} & \\
				\textbf{Test B} & + & - \\ \hline
				+ & 2925 & 2100 \\
				- & 75 & 4900\\
			\end{tabular}
		\end{column}
	\end{columns}
	\vspace{10 pt}
	\begin{itemize}
		\item With both Test A and Test B, 97.5\% of those who used drugs had a positive test result
		\item With Test A, the probability that a positive test result comes from a person who \emph{did not do} drugs is $\frac{450}{2925 + 450} = 13.3\%$
		\item With Test B, the probability that a positive test result comes from a person who \emph{did not do} drugs is $\frac{2100}{2925 + 2100}=41.8\%$
	\end{itemize}
\end{frame}

\begin{frame}{Bayes' Formula}
	\begin{itemize}
		\item \emph{\textbf{Bayes' formula:}} If $A$ and $B$ are events with $0 < P(A) < 1$ and $0 < P(B) < 1$, then:
		\begin{gather*}
		P(A|B) = \frac{P(B|A) P(A)}{P(B|A) P(A) + P(B|A^c) P(A^c)}
		\end{gather*}
		\item Let's calculate the probability that a given person did do drugs ($+$Drugs), given a positive test ($+$Test) for test A
	\end{itemize}
\end{frame}

\begin{frame}{Bayes' Formula}
\begin{itemize}
	\item Let's calculate the probability that a given person did do drugs ($+$Drugs), given a positive test ($+$Test) for test A
	\begin{center}
		\begin{tabular}{c|cc}
			& \textbf{Drug use} & \\
			\textbf{Test A} & + & - \\ \hline
			+ & 2925 & 450 \\
			- & 75 & 6550\\
		\end{tabular}
	\end{center}
{\scriptsize
\begin{align*}
P(\text{+Drugs}|\text{+Test}) &= \frac{P(\text{+Test}|+\text{Drugs}) P(\text{+Drugs})}{P(\text{+Test}|\text{+Drugs}) P(\text{+Drugs}) + P(\text{+Test}|\text{-Drugs}) P(\text{-Drugs})} \\
&= \frac{\frac{2925}{3000} \frac{3000}{10000}}{\frac{2925}{3000} \frac{3000}{10000} + \frac{450}{7000}\frac{7000}{10000}} = \frac{\frac{2925}{10000}}{\frac{2925}{10000}+\frac{450}{10000}} \\
&= \frac{2925}{2925 + 450} = 0.867
\end{align*}
}
\item For test A, $P(\text{+Drugs}|\text{+Test}) = 0.867$
\item For test B, $P(\text{+Drugs}|\text{+Test}) = 0.582$ 
\end{itemize}
\end{frame}

\begin{frame}{Diagnostic tests}
Some important terms about diagnostic tests...
	\begin{itemize}
		\item \textbf{\emph{False positive:}} A false positive occurs when a diagnostic test gives a positive reading, but this conclusion is false
		\begin{itemize}
			\item For test A, the False Positive Rate is: 0.133
			\item For test B, the False Positive Rate is: 0.418
		\end{itemize}
		\item \textbf{\emph{False negative:}} A false positive occurs when a diagnostic test gives a negative reading, but this conclusion is false
		\begin{itemize}
			\item For both test A and B, the False Negative Rate is: 0.025
		\end{itemize}
		\item \textbf{\emph{Sensitivity:}} The sensitivity of a diagnostic test is the True Positive Rate
		\begin{itemize}
			\item For both test A and B, the sensitivity is: 0.975
		\end{itemize}
		\item \textbf{\emph{Specificity:}} The specificity of a diagnostic test is the True Negative Rate
		\begin{itemize}
			\item For test A, the specificity is: 0.867
			\item For test B, the specificity is: 0.582
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Motivation}
Imagine you are the manager of a small airline that flys super important people around. You need to test your pilots for drugs. I manufacture a drug test and tell you that if a person has done drugs, there is a 97.5\% chance we will catch them (positive test). You test your pilots, and 3 of them fail. One of the drug test failures, Sally, claims she is innocent. Should you believe her? 

\vspace{10pt}
Answer: If the false positive rate is high (also meaning specificity is low), then we catch a lot of innocent people (possibly Sally). If the false positive rate is low (also meaning specificity is high), then we don't catch a lot of innocent people (Sorry Sally, we know what you did last summer)
\end{frame}

\begin{frame}{Bayes' Formula}

\begin{itemize}
	\item Bayes' Formula can be extended to multiple events
	\item[]
	\item In our last example we were interested in $P(A|B)$ where A was the event that someone did use drugs and $B$ was a positive drug test
	\begin{itemize}
		\item Events $B$ are called observable events
		\item Events $A$ are called states of nature
	\end{itemize}
	\item[]
	\item Example observable events:
	\begin{itemize}
		\item $B_1$ is the event of a positive drug test
		\item $B_2$ is the event of a negative drug test
		\item $B_3$ is the event of an ``inconclusive'' drug test
	\end{itemize}
	\item[]
	\item Example states of nature:
	\begin{itemize}
		\item $A_1$ the person did not use and was not exposed to drugs
		\item $A_2$ the person did not use but was exposed to drugs
		\item $A_3$ the person did use drugs
	\end{itemize}
	
\end{itemize}
\end{frame}

\begin{frame}{Bayes' Formula}
	\begin{itemize}
		\item If $A_1, A_2, \hdots, A_k$ are $k$ mutually exclusive states of nature, and if $B_1, B_2, \hdots, B_m$ are $m$ possible, mutually exclusive, observable events, then:
		\begin{align*}
		P(A_i|B_j) &= \frac{P(B_j|A_i)P(A_i)}{P(B_j|A_1)P(A_1) + P(B_j|A_2)P(A_2) + \hdots + P(B_j|A_k)P(A_k)} \\
		&= \frac{P(B_j|A_i)P(A_i)}{\sum_i P(B_j|A_i)P(A_i)}
		\end{align*}
	\end{itemize}
\end{frame}

\begin{frame}{Bayes' Formula}{Titanic Example}
	\begin{itemize}
		\item Let $A_1$ be the event a passenger is in 1\textsuperscript{st} Class, $A_2$ in 2\textsuperscript{nd}, $A_3$ in 3\textsuperscript{rd}, and $A_4$ in the crew; Let $B_1$ be the event a passenger survived, let $B_2$ be the event the passenger did not survive
		\item[]
		\item Let's calculate $P(A_1|B_1)$, $P(A_2|B_1)$, $P(A_3|B_1)$, and $P(A_4|B_1)$:
		{\scriptsize
		\begin{align*}
			P(A_1|B_1) &= \frac{P(B_1|A_1)P(A_1)}{P(B_1|A_1)P(A_1) + P(B_1|A_2)P(A_2) + P(B_1|A_3)P(A_3) + P(B_1|A_4)P(A_4)} \\
			&= \frac{\frac{203}{325}\frac{325}{2201}}{\frac{203}{325}\frac{325}{2201} + \frac{118}{285}\frac{285}{2201} + \frac{178}{706}\frac{706}{2201} + \frac{212}{885}\frac{885}{2201}} \\
			&= \frac{0.092}{0.092 + 0.054 + 0.081 + 0.096} \\
			&= \frac{0.092}{0.323} = 0.285
		\end{align*}}
	\end{itemize}
\end{frame}

\begin{frame}
	\begin{align*}
		P(A_1|B_1) &= \frac{0.092}{0.092 + 0.054 + 0.081 + 0.096} = 0.285 \\ \\
		P(A_2|B_1) &= \frac{0.054}{0.092 + 0.054 + 0.081 + 0.096} = 0.167\\ \\
		P(A_3|B_1) &= \frac{0.081}{0.092 + 0.054 + 0.081 + 0.096} = 0.251\\ \\
		P(A_4|B_1) &= \frac{0.096}{0.092 + 0.054 + 0.081 + 0.096} = 0.297\\
	\end{align*}
\end{frame}

\end{document}